<!DOCTYPE html>
<html lang="zh-cn" >
<head>
	<meta name="generator" content="Hugo 0.60.1" />
  <meta charset="utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>

  
  <meta name="author"
        content="monsterxx03"/>

  

  

  
  <link rel="canonical" href="https://blog.monsterxx03.com/"/>

  
  <link rel="alternate" type="application/rss&#43;xml" href="https://blog.monsterxx03.com/index.xml">
  

  <title>Shining Moon</title>

  <link rel="shortcut icon" href="https://blog.monsterxx03.com/images/favicon.ico"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/animate.min.css"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/remixicon.css"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/zozo.css"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/highlight.css"/>

  
  
</head>

<body>
<div class="main animated">
  <div class="nav_container animated fadeInDown">
  <div class="site_nav" id="site_nav">
    <ul>
      
      <li>
        <a href="/">Home</a>
      </li>
      
      <li>
        <a href="/posts/">Archive</a>
      </li>
      
      <li>
        <a href="/about/">About</a>
      </li>
      
      <li>
        <a href="/tags">Tags</a>
      </li>
      
    </ul>
  </div>
  <div class="menu_icon">
    <a id="menu_icon"><i class="remixicon-links-line"></i></a>
  </div>
</div>

  <div class="header animated fadeInDown">
  <div class="site_title_container">
    <div class="site_title">
      <h1>
        <a href="https://blog.monsterxx03.com">
          <span>Shining Moon</span>
          <img width="90px" src="https://blog.monsterxx03.com/logo.png"/>
        </a>
      </h1>
    </div>
    <div class="description">
      <p class="sub_title">百种弊病,皆从懒生</p>
      <div class="my_socials">
        
        
        <a href="https://github.com/monsterxx03" title="github" target="_blank"><i class="remixicon-github-fill"></i></a>
        
        
        <a href="https://blog.monsterxx03.com/index.xml" type="application/rss+xml" title="rss" target="_blank"><i class="remixicon-rss-fill"></i></a>
      </div>
    </div>
  </div>
</div>

  <div class="content">
    


<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2018/02/23/glow-infra-evolution/'>Glow Infra Evolution</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>Glow data infrastructure 的演化 Glow 一向是一个 data driven 做决策的公司，稳定高效的平台是必不可少的支撑, 本文总结几年里公司 data infrastructure 的演进过程. 结合业务特点做技术选型和实现时候的几个原则: real time 分析的需求不高，时间 delta 控制在1 小时以内可接受 . 支持快速的交互式查询. 底层平台尽量选择 AWS 托管服务, 减少维护成本. 遇到故障, 数据可以 delay 但不能丢. 可回溯历史数据. 成本可控. 用到的 AWS 服务: 数据存储和查询: S3, Redshift (spectrum), Athena ETL: DMS, EMR, Kinesis, Firehose, Lambda 开源软件: td-agent, maxwell 数据来源: 线上......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2018.02.23</span>
        </span>
        
        <span class="field tags">
          <i class="remixicon-stack-line"></i>
          
          <a href="https://blog.monsterxx03.com/tags/redshift/">redshift</a>
          
          <a href="https://blog.monsterxx03.com/tags/spectrum/">spectrum</a>
          
          <a href="https://blog.monsterxx03.com/tags/athena/">athena</a>
          
          <a href="https://blog.monsterxx03.com/tags/glow/">glow</a>
          
          <a href="https://blog.monsterxx03.com/tags/data-infra/">data-infra</a>
          
        </span>
        
      </div>
    </div>
  </div>
</div>

<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2018/02/01/get-real-client-ip-on-aws/'>Get Real Client Ip on AWS</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>If you run a webserver on AWS, get real client ip will be tricky if you didn't configure server right and write code correctly.
Things related to client real ip:
 CloudFront (cdn) ALB (loadbalancer) nginx (on ec2) webserver (maybe a python flask application).  Request sequence diagram will be like following:
User's real client ip is forwarded by front proxies one by one in head X-Forwarded-For.
For CloudFront:
 If user's req header don't have X-Forwarded-For, it will set user's ip(from tcp connection) in X-Forwarded-For If user's req already have X-Forwarded-For, it will append user's ip(from tcp connection) to the end of X-Forwarded-For  For ALB, rule is same as CloudFront, so the X-Forwarded-For header pass to nginx will be the value received from CloudFront + CloudFront's ip.
For nginx, things will be tricky depends on your config.
Things maybe involved in nginx:
 real ip module proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for;  If you didn't use real ip module, you need to pass X-Forwarded-For head explictly.
proxy_set_header X-Forwarded-For $proxy_add_x_forwarded_for; will append ALB's ip to the end of X-Forwarded-For header received from ALB.
So X-Forwarded-For header your webserver received will be user ip,cloudfront ip, alb ip
Or you can use real ip module to trust the value passed from ALB.......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2018.02.01</span>
        </span>
        
        <span class="field tags">
          <i class="remixicon-stack-line"></i>
          
          <a href="https://blog.monsterxx03.com/tags/lang-en/">lang-en</a>
          
          <a href="https://blog.monsterxx03.com/tags/aws/">AWS</a>
          
          <a href="https://blog.monsterxx03.com/tags/cloudfront/">CloudFront</a>
          
          <a href="https://blog.monsterxx03.com/tags/alb/">ALB</a>
          
        </span>
        
      </div>
    </div>
  </div>
</div>

<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2017/12/15/dynamodb/'>DynamoDB</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>DynamoDB 是 AWS 的托管 NoSQL 数据库，可以当作简单的 KV 数据库使用，也可以作为文档数据库使用. Data model 组织数据的单位是 table, 每张 table 必须设置 primary key, 可以设置可选的 sort key 来做索引. 每条数据记作一个 item, 每个 item 含有一个或多个 attribute, 其中必须包括 primary key. attribute 对应的 value 支持以下几种类型: Number, 由于 DynamoDB 的传输协议是 http + json, 为了跨语言的兼容性, number 一律会被转成 string 传输. Binary, 用来表示任意的二进制数据，会用 base64 encode 后传输. Boolean, true or false Null Document 类型包含 List 和 Map, 可以互相嵌套. List, 个数无限制, 总大小......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2017.12.15</span>
        </span>
        
        <span class="field tags">
          <i class="remixicon-stack-line"></i>
          
          <a href="https://blog.monsterxx03.com/tags/aws/">AWS</a>
          
          <a href="https://blog.monsterxx03.com/tags/database/">Database</a>
          
          <a href="https://blog.monsterxx03.com/tags/nosql/">NoSQL</a>
          
          <a href="https://blog.monsterxx03.com/tags/server-infra/">server-infra</a>
          
        </span>
        
      </div>
    </div>
  </div>
</div>

<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2017/12/10/handle-outage/'>Handle outage</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>A few weeks ago, production environment came to an outage, solve it cost me 8 hours (from 3am to 11am) although total down time is not long, really a bad expenrience. Finally, impact was mitigated, and I'm working on a long term solution. I learned some important things from this accident.
The outage I received alarms about live performance issue at 3am, first is server latency increaing, soon some service's health check failed due to high load.
I did following:
 Check monitor Identify the problem is caused by KV system  Okay, problem is here, I know the problem is KV system's performance issue. But I can't figure out the root case right now, I need a temporary solution. Straightward way is redirect traffic to slave instance. But I know it won't work (actually it is true), I come to similar issue before, did a fix for it, but seems it doesn't work.
The real down time was not long, performance recovered to some degree soon, but latency was still high, not normal. I monitored it for long time, and tried to find out the root case until morning. Since traffic was growing when peak hour coming, performance became problem again.......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2017.12.10</span>
        </span>
        
        <span class="field tags">
          <i class="remixicon-stack-line"></i>
          
          <a href="https://blog.monsterxx03.com/tags/lang-en/">lang-en</a>
          
          <a href="https://blog.monsterxx03.com/tags/server-infra/">server-infra</a>
          
        </span>
        
      </div>
    </div>
  </div>
</div>

<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2017/10/14/aws-dms-notes/'>AWS DMS notes</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>AWS's DMS (Data migration service) can be used to do incremental ETL between databases. I use it to load data from RDS (MySQL) to Redshift.
It works, but have some concerns. Take some notes when doing this project.
Prerequisites Source RDS must:
 Enable automatic backups Increase binlog remain time, call mysql.rds_set_configuration('binlog retention hours', 24); Set binlog_format to ROW. Privileges on source RDS: REPLICATION CLIENT , REPLICATION SLAVE , SELECT on replication target tables  DDL on source table Redshift has some limits on change columns:
 New column only must be added in the end Can't rename columns  So for DDL on source MySQL, you can't add columns at non end postition, otherwise data in target table will corrupt. I disabled ddl changes target db:
 &quot;ChangeProcessingDdlHandlingPolicy&quot;:{ &quot;HandleSourceTableDropped&quot;:false, &quot;HandleSourceTableTruncated&quot;:false, &quot;HandleSourceTableAltered&quot;:false },  If source table schema changed, I just drop and reload target table on console.
Control write speed on Redshift Since Redshift is an OLAP database, write operation is slow and concurrency is low, streaming data directly will have big impact on it.
And we have may analysis jobs running on redshift all the time, directly streaming will lock target table and make my analysis jobs timeout.......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2017.10.14</span>
        </span>
        
        <span class="field tags">
          <i class="remixicon-stack-line"></i>
          
          <a href="https://blog.monsterxx03.com/tags/lang-en/">lang-en</a>
          
          <a href="https://blog.monsterxx03.com/tags/aws/">AWS</a>
          
          <a href="https://blog.monsterxx03.com/tags/dms/">DMS</a>
          
          <a href="https://blog.monsterxx03.com/tags/data-infra/">data-infra</a>
          
        </span>
        
      </div>
    </div>
  </div>
</div>

<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2017/09/29/get-all-invalid-ptr-record-on-route53/'>Get all invalid PTR record on  Route53</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>I use autoscaling group to manage stateless servers. Servers go up and down every day.
Once server is up, I will add a PTR record for it’s internal ip. But when it’s down, I didn’t cleanup the PTR record. As times fly, a lot of invalid PTR records left in Route53.
To cleanup those PTR records realtime, you can write a lambda function, use server termination event as trigger. But how to cleanup the old records at once?
Straightforward way is write a script to call AWS API to get a PTR list, get ip from record, test whether the ip is live, if not, delete it.
Since use awscli to delete a Route53 record is very troublesome (involve json format), you’d better write a python script to delete them. I just demo some ideas to collect those records via shell.
You can do it in a single line, but make things clear and easy to debug, I split it into several steps.
Get PTR record list aws route53 list-resource-record-sets --hosted-zone-id xxxxx --query &quot;ResourceRecordSets[?Type=='PTR'].Name&quot; | grep -Po '&quot;(.+?)&quot;' | tr -d \&quot; &gt; ptr.txt  ptr.txt will contain lines like:
1.0.0.10.in-addr.arpa. 2.0.0.10.in-addr.arpa.  Get ip list from PTR records cat ptr.......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2017.09.29</span>
        </span>
        
        <span class="field tags">
          <i class="remixicon-stack-line"></i>
          
          <a href="https://blog.monsterxx03.com/tags/lang-en/">lang-en</a>
          
          <a href="https://blog.monsterxx03.com/tags/aws/">AWS</a>
          
          <a href="https://blog.monsterxx03.com/tags/route53/">route53</a>
          
        </span>
        
      </div>
    </div>
  </div>
</div>

<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2017/08/19/build-private-staticwebsite-on-s3/'>Build private static website on S3</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>Build static website on S3 is very easy, but by default, it can be accessed by open internet.It will be super helpful if we can build website only available in VPC. Then we can use it to host internal deb repo, doc site…
Steps are very easy, you only need VPC endpoints and S3 bucket policy.
AWS api is open to internet, if you need to access S3 in VPC, your requests will pass through VPC’s internet gateway or NAT gateway. With VPC endpoints(can be found in VPC console), your requests to S3 will go through AWS’s internal network. Currently, VPC endpoints only support S3, support for dynamodb is in test.
To restrict S3 bucket only available in your VPC, need to set bucket policy (to host static website, enable static website support first). At first, I didn’t check doc, try to restrict access by my VPC ip cidr, but it didn’t work, I need to restrict by VPC endpoint id:
{ &quot;Version&quot;: &quot;2012-10-17&quot;, &quot;Id&quot;: &quot;Policy1415115909152&quot;, &quot;Statement&quot;: [ { &quot;Sid&quot;: &quot;Access-to-specific-VPCE-only&quot;, &quot;Principal&quot;: &quot;*&quot;, &quot;Action&quot;: &quot;s3:GetObject&quot;, &quot;Effect&quot;: &quot;Allow&quot;, &quot;Resource&quot;: [&quot;arn:aws:s3:::my_secure_bucket&quot;, &quot;arn:aws:s3:::my_secure_bucket/*&quot;], &quot;Condition&quot;: { &quot;StringEquals&quot;: { &quot;aws:sourceVpce&quot;: &quot;vpce-1a2b3c4d&quot; } } } ] }  BTW, if you can config bucket policy restrict on VPC directly, with VPC endpoint you can limit to subnets.......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2017.08.19</span>
        </span>
        
        <span class="field tags">
          <i class="remixicon-stack-line"></i>
          
          <a href="https://blog.monsterxx03.com/tags/lang-en/">lang-en</a>
          
          <a href="https://blog.monsterxx03.com/tags/aws/">AWS</a>
          
          <a href="https://blog.monsterxx03.com/tags/s3/">S3</a>
          
        </span>
        
      </div>
    </div>
  </div>
</div>

<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2017/08/13/%E6%97%85%E8%A1%8C%E6%95%A3%E8%AE%B0/'>旅行散记</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>前阵子总有点心烦意乱的，生活上的，家里的，堵在一块，弄得自己都有点疲惫了，8月初的时候去日本东北逛了一圈，恰逢当地祭奠密集期，也就凑了把热闹，还挺有意思。 行程: 上海 -&gt; 东京 -&gt; 盛冈 -&gt; 八户 -&gt; 十和田湖 -&gt; 青森 -&gt; 弘前 -&gt; 东京 -&gt; 上海, 满满当当的7天, 懒得贴图，瞎记一点。 盛冈是岩手县的首府，但刚到的时候感觉真是个大乡下啊，大白天，出了车站区域，步行1公里多的时间里只碰到了2个人，一个桥下睡觉的大叔，一个遛狗的，像个......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2017.08.13</span>
        </span>
        
      </div>
    </div>
  </div>
</div>

<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2017/07/21/use-redshift-spectrum-to-do-query-on-s3/'>Use redshift spectrum to do query on s3</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>使用 redshift spectrum 查询 S3 数据 通常使用 redshift 做数据仓库的时候要做大量的 ETL 工作，一般流程是把各种来源的数据捣鼓捣鼓丢到 S3 上去，再从 S3 倒腾进 redshift. 如果你有大量的历史数据要导进 redshift，这个过程就会很痛苦，redshift 对一次倒入大量数据并不友好，你要分批来做。 今年4月的时候， redshift 发布了一个新功能 spectrum, 可以从 redshift 里直接查询 s3 上的结构化数据。最近把部分数据仓库直接迁移到了 spectrum, 正好来讲讲。 动机 Glow 的数据仓库建在 redshift 上， 又分成了两个......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2017.07.21</span>
        </span>
        
        <span class="field tags">
          <i class="remixicon-stack-line"></i>
          
          <a href="https://blog.monsterxx03.com/tags/aws/">AWS</a>
          
          <a href="https://blog.monsterxx03.com/tags/redshift/">Redshift</a>
          
          <a href="https://blog.monsterxx03.com/tags/spark/">spark</a>
          
          <a href="https://blog.monsterxx03.com/tags/data-infra/">data-infra</a>
          
        </span>
        
      </div>
    </div>
  </div>
</div>

<div class="post animated fadeInDown">
  <div class="post_title">
    <h2><a href='/2017/07/15/enable-coredump-on-ubuntu-16.04/'>Enable coredump on ubuntu 16.04</a></h2>
  </div>
  
  <div class="list">
    <div class="post_content markdown">
      <p>Coredump file is useful for debuging program crash. This post will show several settings related to coredump.
Enable coredump If you run program from shell , enable coredump via unlimit -c unlimited， then check unlimit -a | grep core, if it shows unlimited, coredump is enabled for your current session.
If your program is hosted by systemd, you need to edit your program’s service unit file’s [Service] section, add LimitCORE=infinity to enable coredump.
coredump location Coredump file’s location is determined by kernerl parameter kernel.core_pattern.
On ubuntu 16.04 kernel.core_pattern default value is |/usr/share/apport/apport %p %s %c %P. Leading | means pass coredump file to following program. %p %c %P is used to create dump filename, their meaning can check via man core. apport will save dump file in /var/crash
If your default disk partition don’t have enough space to hold dump file, you can change kernel.core_pattern to another location, eg: /mnt/core/%e-%t.%P. If redis-server crashes, the dump file will be something like /mnt/core/redis-server-1500000000.1452. Also ensure crash process’s running user have write privilege on target location.
systemd-coredump You can install systemd-coredump to control dump file deeply, like: size, compression….
Its config file is /etc/systemd/coredump.conf.
After install, it will change kernel.core_pattern to |/lib/systemd/systemd-coredump %P %u %g %s %t 9223372036854775808 %e.......</p>
    </div>
  </div>
  
  <div class="post_footer">
    <div class="meta">
      <div class="info">
        <span class="field">
          <i class="remixicon-map-pin-time-line"></i>
          <span class="date">2017.07.15</span>
        </span>
        
        <span class="field tags">
          <i class="remixicon-stack-line"></i>
          
          <a href="https://blog.monsterxx03.com/tags/coredump/">coredump</a>
          
          <a href="https://blog.monsterxx03.com/tags/system/">system</a>
          
          <a href="https://blog.monsterxx03.com/tags/ubuntu/">ubuntu</a>
          
        </span>
        
      </div>
    </div>
  </div>
</div>


<div class="pagination">
  
  
  <a href="/page/5/" class="pre">
    返回上一页
  </a>
  
  
  <a href="/page/7/" class="next">
    阅读更多文章
  </a>
  
  
</div>

  </div>
</div>
<footer class="footer">
  <div class="powered_by">
    <a href="https://zeuk.me">Designed by Zeuk,</a>
    <a href="http://www.gohugo.io/">Proudly published with Hugo</a>
  </div>

  <div class="footer_slogan">
    <span></span>
  </div>
</footer>



<script src="https://blog.monsterxx03.com/js/jquery-3.3.1.min.js"></script>
<script src="https://blog.monsterxx03.com/js/zozo.js"></script>
<script src="https://blog.monsterxx03.com/js/highlight.pack.js"></script>
<link  href="https://blog.monsterxx03.com/css/fancybox.min.css" rel="stylesheet">
<script src="https://blog.monsterxx03.com/js/fancybox.min.js"></script>

<script>hljs.initHighlightingOnLoad()</script>


  <script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>



<script type="application/javascript">
var doNotTrack = false;
if (!doNotTrack) {
	window.ga=window.ga||function(){(ga.q=ga.q||[]).push(arguments)};ga.l=+new Date;
	ga('create', 'UA-98667627-1', 'auto');
	
	ga('send', 'pageview');
}
</script>
<script async src='https://www.google-analytics.com/analytics.js'></script>



</body>
</html>
