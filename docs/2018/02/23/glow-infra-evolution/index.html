<!DOCTYPE html>
<html lang="zh-cn" >
<head>
  <meta charset="utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>

  
  <meta name="author"
        content="monsterxx03"/>

  
  <meta name="description" content="Glow data infrastructure 的演化 Glow 一向是一个 data driven 做决策的公司，稳定高效的平台是必不可少的支撑, 本文总结几年里公司 data infrastructure 的演进过程. 结合业务特点做技术选型和实现时候的几个原则: real time 分析的需求不高，时间 delta 控制在1 小时以内可接受 . 支持快速的交互式查询. 底层平台尽量选择 AWS 托管服务, 减少维护成本. 遇到故障, 数据可以 delay 但不能丢. 可回溯历史数据. 成本可控. 用到的 AWS 服务: 数据存储和查询: S3, Redshift (spectrum), Athena ETL: DMS, EMR, Kinesis, Firehose, Lambda 开源软件: td-agent, maxwell 数据来源: 线上"/>
  

  

  
  <link rel="canonical" href="https://blog.monsterxx03.com/2018/02/23/glow-infra-evolution/"/>

  

  <title>Glow Infra Evolution &middot; Shining Moon</title>

  <link rel="shortcut icon" href="https://blog.monsterxx03.com/images/favicon.ico"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/animate.min.css"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/remixicon.css"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/zozo.css"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/highlight.css"/>

  
  
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/home.css">
  
</head>

<body>
<div class="main animated">
  <div class="nav_container animated fadeInDown">
  <div class="site_nav" id="site_nav">
    <ul>
      
      <li>
        <a href="/">Home</a>
      </li>
      
      <li>
        <a href="/posts/">Archive</a>
      </li>
      
      <li>
        <a href="/about/">About</a>
      </li>
      
      <li>
        <a href="/tags">Tags</a>
      </li>
      
    </ul>
  </div>
  <div class="menu_icon">
    <a id="menu_icon"><i class="remixicon-links-line"></i></a>
  </div>
</div>

  <div class="header animated fadeInDown">
  <div class="site_title_container">
    <div class="site_title">
      <h1>
        <a href="https://blog.monsterxx03.com">
          <span>Shining Moon</span>
          <img width="90px" src="https://blog.monsterxx03.com/logo.png"/>
        </a>
      </h1>
    </div>
    <div class="description">
      <p class="sub_title">百种弊病,皆从懒生</p>
      <div class="my_socials">
        
        
        <a href="https://github.com/monsterxx03" title="github" target="_blank"><i class="remixicon-github-fill"></i></a>
        
        
        <a href="https://blog.monsterxx03.com/index.xml" type="application/rss+xml" title="rss" target="_blank"><i class="remixicon-rss-fill"></i></a>
      </div>
    </div>
  </div>
</div>

  <div class="content">
    <div class="post_page">
      <div class="post animated fadeInDown">
        <div class="post_title post_detail_title">
          <h2><a href='/2018/02/23/glow-infra-evolution/'>Glow Infra Evolution</a></h2>
          <span class="date">2018.02.23</span>
        </div>
        <div class="post_content markdown"><h1 id="glow-data-infrastructure-的演化">Glow data infrastructure 的演化</h1>
<p>Glow 一向是一个 data driven 做决策的公司，稳定高效的平台是必不可少的支撑, 本文总结几年里公司 data infrastructure 的演进过程.</p>
<p>结合业务特点做技术选型和实现时候的几个原则:</p>
<ol>
<li>real time 分析的需求不高，时间 delta 控制在1 小时以内可接受 .</li>
<li>支持快速的交互式查询.</li>
<li>底层平台尽量选择 AWS 托管服务, 减少维护成本.</li>
<li>遇到故障, 数据可以 delay 但不能丢.</li>
<li>可回溯历史数据.</li>
<li>成本可控.</li>
</ol>
<p>用到的 AWS 服务:</p>
<ul>
<li>数据存储和查询:  S3, Redshift (spectrum), Athena</li>
<li>ETL: DMS, EMR, Kinesis, Firehose, Lambda</li>
</ul>
<p>开源软件: td-agent, maxwell</p>
<p>数据来源:</p>
<ol>
<li>线上业务数据库</li>
<li>用户活动产生的 metrics log</li>
<li>从各种第三方服务 api 拉下来的数据 (email之类)</li>
</ol>
<h2 id="最早期">最早期</h2>
<p>刚开始的时候业务单纯，数据量也少, 所有数据都用 MySQL 存储，搭了台 slave, 分析查询都在 slave 上进行.</p>
<p><img src="/posts/images/glow-infra/1.png" alt="1"></p>
<p>优点是简单, 缺点也很明显:</p>
<ol>
<li>无法支撑大数据量</li>
<li>MySQL 语法太弱, 不利于分析</li>
<li>metrics log 和业务数据库不在一起， 无法做 join</li>
<li>贵</li>
</ol>
<h2 id="引入-redshift">引入 Redshift</h2>
<p>随着业务发展，MySQL 已经放不下 metrics log 了，更换更大的 instance 不划算, 性能也跟不上，算个 retention 要半个小时, 每天的 metrics report 越出越慢.</p>
<p>这个阶段，我们要引入数据仓库, 用了 AWS 的 Redshift.</p>
<p>当时也写过关于 Redshift 使用和优化的文章: <a href="http://tech.glowing.com/cn/redshift-as-data-warehouse/">redshift as data warehouse</a></p>
<p>几个考虑:</p>
<ol>
<li>columnar storage 减少存储成本, 提高查询效率 (metrics log 设计成了很宽的 flatten table)</li>
<li>基于 Postgresql, 有现成的 GUI 客户端和 driver, SQL 语法也比 MySQL 强.</li>
<li>和 S3 良好的交互(load/unload data), 方便 ETL.</li>
<li>现成的集群支持,可以横向扩容.</li>
</ol>
<p><img src="/posts/images/glow-infra/2.png" alt="2"></p>
<p>现在，我们可以把线上数据和 metrics log 放在一个 DB 里了，极大简化了分析查询.</p>
<p>metrics log 是 append-only 的数据，不会修改，所以直接用每小时的 cronjob 导进 Redshift， delay 1 小时, 解决了 metrics log 量大的问题.</p>
<p>这一阶段, 线上数据库仍旧不算很大，做所有表的每天全量更新可以接受,数据延迟在1天,实现上是自己写的脚本把数据 dump 到 S3, 再 copy 进 Redshift.</p>
<p>但是每天的 metrics report 中很多指标是需要最新数据的，一天的延迟不能接受, 怎么办? 自己写了个很简单的基于 DAG 的 ETL 管理框架, 在 report 中指定依赖的 table, 跑 report 前会先把依赖的 table 导完保证里面有最新数据，其余没有被依赖的 table 就慢慢导.</p>
<p>当前阶段的问题:</p>
<ol>
<li>业务数据库1天的 delay 对分析可接受，但是 QA 和 developer 有时也会需要这些数据做 debug, 1 天就不够了.</li>
<li>业务数据库全量更新, 只是当前阶段可接受, 长远来看不行.</li>
<li>metrics log 增量很快, 现在是全存 SSD 的 Redshift 集群, 可预见的未来当前架构成本会很高.</li>
</ol>
<h2 id="减少-metrics-log-的存储成本">减少 metrics log 的存储成本</h2>
<p>metrics log 存进 Redshift 之后, 因为能对数据做按行压缩, 存储成本已经比之前 MySQL 低很多了, 我们的压缩比大概在 1:5.</p>
<p>但数据增长实在太快,Redshift 扩容了几次之后, 我们觉得有必要消减成本.</p>
<p>metrics log 是基于时间的数据, 产品分析一般也就需要最近几个月的数据，半年前的数据偶尔会用下,
所以新数据是 hot spot, 老数据就比较冷, 考虑将老数据迁移到便宜的存储方案上去，速度慢点也能接受.</p>
<p>当时的做法, 是另起了一个 HDD 的集群来存储老数据.SSD 集群只保留最近几个月的数据. 算下来存储大概少了30% 的费用，长远看省的更多.</p>
<p>带来的问题:</p>
<ol>
<li>2 个集群，管理成本上升.</li>
<li>为了做分析, 线上数据库在两个集群中都复制了一遍, 太冗余.</li>
<li>HDD 集群迟早也是要扩容的.</li>
</ol>
<h2 id="减少线上数据库到-redshift-的-delay">减少线上数据库到 Redshift 的 delay</h2>
<p>前面说过线上数据库是每天全量更新到 Redshift 的, 随着时间的推移, ETL 运行的时间越来越长, 要想办法做增量更新.</p>
<p>原理很简单，拉 MySQL 的 binlog， 解析后就能增量更新 Redshift 里数据了, 正好 AWS 的 DMS
差不多在这时候支持将数据导入 Redshift 了, 所以就把这块的 ETL 迁移到 DMS 上去.</p>
<p><img src="/posts/images/glow-infra/3.png" alt="3"></p>
<p>解决了:</p>
<ol>
<li>线上数据 delay 过长</li>
<li>metrics report 不再需要关心依赖哪些 table</li>
<li>简化 ETL</li>
</ol>
<p>几个注意的地方:</p>
<ol>
<li>DMS 默认更新频率大概 1 min 一次, 但我们的 Redshift 里几乎每时每刻都有 分析的 query 在跑，而 Redshift 并发上限比较低(50qps), 实测 DMS 对 Redshift 性能影响很大, 所以我控制了 DMS 的更新频率到 1 小时, 可以调节它的 BatchApplyTimeout 实现.</li>
<li>Redshift 添加新列只能在表末尾, 而且不能改现有列属性, MySQL 里做 DDL 会导致 DMS task 失败, 可以单独把做 DDL 的表 reload.</li>
<li>DMS 的配置很复杂，一定要用代码管理起来，不要手工设置, 我用 <a href="https://terraform.io">terraform</a> 来管理 AWS.</li>
</ol>
<h2 id="淘汰掉-hdd-的-redshift-集群">淘汰掉 HDD 的 Redshift 集群</h2>
<p>HDD 的 Redshift 虽然减少了成本，但带来了管理的复杂, hive 和 postgresql 支持 external table, Redshift 也能用多好?</p>
<p>17 年 4 月的时候, Redshift 发布了 spectrum, 终于支持拿 S3 上数据做 external table 啦.</p>
<p>决定把老的 metrics log 数据搬到 S3 上去, 关于 spectrum 的使用, 和 athena 的关系,以前也写过: <a href="http://tech.glowing.com/cn/shi-yong-redshift-spectrum-cha-xun-s3-shu-ju/">使用 Redshift Spectrum 查询 S3 数据</a></p>
<p>每月把上个月的 metrics log 导到 S3 上，用 parquet 格式存储(通过EMR 用 spark 转).parquet 是 columnar 的格式, spectrum 是按扫描数据量收钱的, 比较省钱，同时还能大大加快查询速度.</p>
<p><img src="/posts/images/glow-infra/4.png" alt="4"></p>
<p>好处:</p>
<ol>
<li>解决了两个集群带来的管理复杂.</li>
<li>用 S3 做 data lake，价格进一步降低.</li>
<li>新老数据在一个 DB 里, 方便查询和 join.</li>
</ol>
<h2 id="线上数据的-audit">线上数据的 Audit</h2>
<p>对于部分关键业务表(支付相关)，我们希望从 DB 层记录下它的所有历史更改, 所以需要记下 binlog, 以前也做过，不过只是单纯得把 binlog 拉下来，存到 S3 上去, 由于存的是裸数据，要看比较麻烦.</p>
<p>希望能直接在 redshift 里查询 MySQL 任意一张表的 binlog.</p>
<p><img src="/posts/images/glow-infra/5.png" alt="5"></p>
<p>上图看上去流程很长，是因为这是个一天里完成的速成方案, 其实可以优化.</p>
<p><a href="http://maxwells-daemon.io/">maxwell</a> 是zendesk 开源的一个组件，可以收集 MySQL 的binlog 发送到多种 target (redis/rabbitmq/kiness&hellip;)</p>
<p>kinesis 是 AWS 的消息队列服务，firehose 是 AWS 的 ETL 服务, 用来将 data stream 传输到各种存储系统.</p>
<p>firehose 和 S3 之间为什么夹了个 lambda? 这是因为 firehose 比较傻, 它会一次 flush 多条记录到 S3 上，但每条之间没有分隔，直接拼在一起，所以多条 json 记录变到1行去了, athena 和 redshift 都无法识别. 官方建议在数据源头给每条最后加个<code>\n</code>, 但我又改不了 maxwell 的输出格式，只能先拿 lambda 凑合下.</p>
<p>在 athena 和 redshift 里都对 s3 做了 external table, 原因是在当前的数据格式下(每条记录都是嵌套的json) athena 里查询更方便, 因为它是基于 <a href="https://prestodb.io/">presto</a> 的， 支持嵌套 struct 和 map 结构, 目前 redshift 支持 delimiter 分隔的数据, 实际使用时候需要用一些内置函数提取特定字段, 不是很方便, json 支持在 roadmap 上, 目前还是 athena 更方便.</p>
<p>在 ETL 部分，可以把 firehose 和 lambda 去掉, 自己订阅 kinesis 的数据实现上传 s3.</p>
<h2 id="总结">总结</h2>
<p>以上是 Glow 最近几年基于 AWS 构建 data infrastructure 的过程. 实际实施过程中，最麻烦的还是系统迁移时候老数据的 migration, 在刚转换过去的时候难免会碰到一些坑, 积极试错很有必要.</p>
</div>
        <div class="post_footer">
          
          <div class="meta">
            <div class="info">
              <span class="field tags">
                <i class="remixicon-stack-line"></i>
                
                <a href="https://blog.monsterxx03.com/tags/redshift/">redshift</a>
                
                <a href="https://blog.monsterxx03.com/tags/spectrum/">spectrum</a>
                
                <a href="https://blog.monsterxx03.com/tags/athena/">athena</a>
                
                <a href="https://blog.monsterxx03.com/tags/glow/">glow</a>
                
                <a href="https://blog.monsterxx03.com/tags/data-infra/">data-infra</a>
                
              </span>
            </div>
          </div>
          
        </div>
      </div>
    <div id="disqus_thread"></div>
<script type="application/javascript">
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mx03" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
      
    </div>
  </div>
  <a id="back_to_top" href="#" class="back_to_top"><span>△</span></a>
</div>
<footer class="footer">
  <div class="powered_by">
    <a href="https://zeuk.me">Designed by Zeuk,</a>
    <a href="http://www.gohugo.io/">Proudly published with Hugo</a>
  </div>

  <div class="footer_slogan">
    <span></span>
  </div>
</footer>



<script src="https://blog.monsterxx03.com/js/jquery-3.3.1.min.js"></script>
<script src="https://blog.monsterxx03.com/js/zozo.js"></script>
<script src="https://blog.monsterxx03.com/js/highlight.pack.js"></script>
<link  href="https://blog.monsterxx03.com/css/fancybox.min.css" rel="stylesheet">
<script src="https://blog.monsterxx03.com/js/fancybox.min.js"></script>

<script>hljs.initHighlightingOnLoad()</script>


  <script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>



<script async src="https://www.googletagmanager.com/gtag/js?id=G-P32CTT1G2G"></script>
<script>
var doNotTrack = false;
if (!doNotTrack) {
	window.dataLayer = window.dataLayer || [];
	function gtag(){dataLayer.push(arguments);}
	gtag('js', new Date());
	gtag('config', 'G-P32CTT1G2G', { 'anonymize_ip': false });
}
</script>



</body>
</html>
