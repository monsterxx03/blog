<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Server-Infra on Shining Moon</title>
    <link>https://blog.monsterxx03.com/tags/server-infra/</link>
    <description>Recent content in Server-Infra on Shining Moon</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <copyright>monsterxx03</copyright>
    <lastBuildDate>Thu, 01 Apr 2021 14:40:30 +0800</lastBuildDate>
    <atom:link href="https://blog.monsterxx03.com/tags/server-infra/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Rolling Upgrade Worker Nodes in EKS</title>
      <link>https://blog.monsterxx03.com/2021/04/01/rolling-upgrade-worker-nodes-in-eks/</link>
      <pubDate>Thu, 01 Apr 2021 14:40:30 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2021/04/01/rolling-upgrade-worker-nodes-in-eks/</guid>
      <description>&lt;p&gt;EKS control plane 的升级是比较简单的, 直接在 aws console 上点下就可以了, 但 worker node 是自己用 asg(autoscaling group) 管理的, 升级 worker node 又不想影响业务是有讲究的.&lt;/p&gt;&#xA;&lt;p&gt;跑在 EKS 里, 且希望不被中断 traffic 的有:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;stateless 的 api server, queue consumer&lt;/li&gt;&#xA;&lt;li&gt;被 redis sentinel 监控着的 redis master/slave&lt;/li&gt;&#xA;&lt;li&gt;用于 cache 的 redis cluster&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;写了个内部工具, 把下面的流程全部自动化了. 这样升级 eks 版本, 需要更换 worker node 时候就轻松多了. 因为这个工具对部署情况做了很多假设和限制, 开源的价值不是很大.&lt;/p&gt;&#xA;&lt;h2 id=&#34;stateless-application&#34;&gt;Stateless application&lt;/h2&gt;&#xA;&lt;p&gt;stateless 的应用全部用 deployment 部署.&lt;/p&gt;&#xA;&lt;p&gt;一般建议的流程是:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;修改 asg 的 launch configuration, 指向新版本的 ami&lt;/li&gt;&#xA;&lt;li&gt;把所有老的 worker node 用 kubectl cordon 标记成 unschedulable&lt;/li&gt;&#xA;&lt;li&gt;关闭 cluster-autoscaler&lt;/li&gt;&#xA;&lt;li&gt;修改 asg 的 desired count, 让 asg 用新 ami 启动新的 worker node&lt;/li&gt;&#xA;&lt;li&gt;用 kubectl drain 把老 worker node 上的 pod evict 掉, 让它们 schedule 到新的 worker node 上.&lt;/li&gt;&#xA;&lt;li&gt;重新开启 cluster autoscaler, 等它把老的闲置 worker node 关闭.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;这里有些问题:&lt;/p&gt;</description>
    </item>
    <item>
      <title>从 twemproxy 迁移到 redis cluster</title>
      <link>https://blog.monsterxx03.com/2020/07/08/%E4%BB%8E-twemproxy-%E8%BF%81%E7%A7%BB%E5%88%B0-redis-cluster/</link>
      <pubDate>Wed, 08 Jul 2020 17:08:40 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2020/07/08/%E4%BB%8E-twemproxy-%E8%BF%81%E7%A7%BB%E5%88%B0-redis-cluster/</guid>
      <description>&lt;p&gt;线上有个 redis 的缓存集群, 跑的还是 3.0, 前面套 twemproxy 做 sharding. 跑了好几年了都很稳定, 但一直有些很不爽的地方, 最近有点时间,决定&#xA;升级到redis 6, 并迁移到 redis cluster 方案.&lt;/p&gt;&#xA;&lt;h3 id=&#34;twemproxy-的工作模式&#34;&gt;twemproxy 的工作模式&lt;/h3&gt;&#xA;&lt;p&gt;twemproxy 的原理很简单, 后面运行 N 个 redis 实例, 应用连到 twemproxy, twemproxy 解析应用发过来的 redis protocol, 根据 key 做 hash, 打散到后面 N 个 redis 实例上.&lt;/p&gt;&#xA;&lt;p&gt;具体打散的方式可以是简单的 hash%N, 也可以用一致性 hash 算法. hash%N 的问题是, 增减节点的时候所有 cache 必然 miss.&lt;/p&gt;&#xA;&lt;p&gt;一致性 hash, 在实现的时候会先弄一个 size 很大的 hash ring(eg: 2^32),这里每个节点被叫做一个虚拟节点, 把虚拟节点的数目叫做 X, 然后将 N 个 redis 实例均匀分布到这个环上, 每个 redis 把它叫做实节点吧, 分配 key&#xA;的时候 hash%X, 得到虚拟节点, 然后顺时针找下一个最近的实节点, 就找到了相应的 redis. 因为虚拟节点的数目是不变的, 增减 redis 实例的数目是改变了实节点的分布, 顺时针找下个实节点的时候还是有一定几率落在以前的&#xA;redis 实例上的, 这在一定程度上减少了 cache 的 miss. 可以看作 hash%N 的优化版本,但不解决本质问题.&lt;/p&gt;</description>
    </item>
    <item>
      <title>编写 postmortem</title>
      <link>https://blog.monsterxx03.com/2020/01/18/%E7%BC%96%E5%86%99-postmortem/</link>
      <pubDate>Sat, 18 Jan 2020 15:20:47 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2020/01/18/%E7%BC%96%E5%86%99-postmortem/</guid>
      <description>&lt;p&gt;成功的经验总是带有点运气成份, 失败则是必然的:). 工作中， 线上环境的问题千奇百怪, 有的来自自己代码 bug, 有的是配置错误, 有时候是第三方的 vendor 成了猪队友. 对于一些排查过程比较困难或具有代表性的问题, 需要记录下来, 一般把这个过程叫做 postmortem(验尸).&lt;/p&gt;&#xA;&lt;p&gt;这篇写一下自己做 postmortem 的过程, 并记录一个最近处理的故障.&lt;/p&gt;&#xA;&lt;h2 id=&#34;postmortem-process&#34;&gt;Postmortem process&lt;/h2&gt;&#xA;&lt;p&gt;我大体分以下几个部分:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;用尽量简练的语句描述清楚在什么时间发生了什么,谁参与了问题的处理(when, what, who)?&lt;/li&gt;&#xA;&lt;li&gt;详细描述解决问题的过程, 包括但不限于:  debug 的过程, 中间的推测, 用到的工具&amp;hellip; (How)&lt;/li&gt;&#xA;&lt;li&gt;如果找到了 root case, 记录下来, 没找到, 记录下当时的 workaround, 有什么副作用. (Why)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;postmortem-case&#34;&gt;Postmortem case&lt;/h2&gt;&#xA;&lt;p&gt;实际的 postmorten 写得更简单一点, 这里把过程中的一些思考也记下来.&lt;/p&gt;</description>
    </item>
    <item>
      <title>聊聊 AWS 的计费模式</title>
      <link>https://blog.monsterxx03.com/2019/12/30/%E8%81%8A%E8%81%8A-aws-%E7%9A%84%E8%AE%A1%E8%B4%B9%E6%A8%A1%E5%BC%8F/</link>
      <pubDate>Mon, 30 Dec 2019 12:08:47 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2019/12/30/%E8%81%8A%E8%81%8A-aws-%E7%9A%84%E8%AE%A1%E8%B4%B9%E6%A8%A1%E5%BC%8F/</guid>
      <description>&lt;p&gt;网上经常有人诟病 AWS 的计费模式复杂, 喜欢国内那种打包式的售卖方式, 这个可能受限于每个公司的财务流程, 预算制定方式, 合不合国情,本文不讨论.&#xA;仅从开发者的角度介绍下 AWS 部分常用 service 的计费方式.&lt;/p&gt;&#xA;&lt;p&gt;PS: 那些为了蹭一年 free plan 然后抱怨什么偷跑流量, 偷偷扣费的大哥就省省吧, AWS 根本不是给个人用的, 老老实实用 lightsail 得了.&lt;/p&gt;&#xA;&lt;h2 id=&#34;ec2&#34;&gt;EC2&lt;/h2&gt;&#xA;&lt;p&gt;EC2 的价格是最复杂的, 一台 EC2 instance 的价格组成:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;instance fee, 实际支付的是 CPU+RAM 的费用&lt;/li&gt;&#xA;&lt;li&gt;EBS fee, server 的根分区都是 EBS volume, 按 EBS 计费(31GB 的 volume 使用 1 小时, 和 1GB 的volume 使用 744 小时价格相同).&lt;/li&gt;&#xA;&lt;li&gt;data transfer fee, 这部分组成比较复杂，简单讲, 入流量免费, 出流量按 GiB 计费, 如果出流量是到 AWS 其他 region, 价格比一般公网便宜, 在内网传输流量, 同一个 available zone 是免费的,&#xA;跨 az 收费.&lt;/li&gt;&#xA;&lt;li&gt;EIP fee, 每台 instance 挂一个 EIP 是免费的(eip 使用状态不收费, 闲置收费), 超过一个 eip, 每个按小时再收费.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;instance fee 又分 on-demand/resersed/spot instance.&lt;/p&gt;</description>
    </item>
    <item>
      <title>集成 opentracing</title>
      <link>https://blog.monsterxx03.com/2019/11/15/%E9%9B%86%E6%88%90-opentracing/</link>
      <pubDate>Fri, 15 Nov 2019 14:05:59 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2019/11/15/%E9%9B%86%E6%88%90-opentracing/</guid>
      <description>&lt;p&gt;之前用过 datadog 的 tracing 功能, 非常好用, 但是很贵(单台30$), 迁移到 k8s 后, 监控迁移到了 prometheus, 也把 datadog 的 tracing 去掉了.datadog 的 tracing 也是 opentracing 的一种实现, 索性就换上开源实现.&lt;/p&gt;&#xA;&lt;p&gt;tracing 系统是分布式系统中很好用的 performance tuning 工具, opentracing 只是一个标准，里面定义了 span, scope, tracer 等概念，但不规定 tracing&#xA;数据应该怎么 encoding, 怎么存储, 跨进程的 span 数据怎么串起来.&lt;/p&gt;&#xA;&lt;p&gt;首先要挑选一个开源的 tracer 实现，tracer 用来接受业务系统发出的 encode 过的 span 数据,并存储，提供一个界面供查询. 我选的是 jaeger, go实现的,部署起来比较轻量级,&#xA;也是 cncf 的项目, 还有个 jaeger-operator 方便部署.&lt;/p&gt;</description>
    </item>
    <item>
      <title> 迁移到 k8s 过程中碰到的问题</title>
      <link>https://blog.monsterxx03.com/2019/07/23/%E8%BF%81%E7%A7%BB%E5%88%B0-k8s-%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%A2%B0%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Tue, 23 Jul 2019 12:32:08 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2019/07/23/%E8%BF%81%E7%A7%BB%E5%88%B0-k8s-%E8%BF%87%E7%A8%8B%E4%B8%AD%E7%A2%B0%E5%88%B0%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      <description>&lt;p&gt;开始把线上流量往 k8s 集群里面导了, 中间碰到了茫茫多的问题 &amp;hellip;&amp;hellip; 记录一下(大多都不是 k8s 的问题).&lt;/p&gt;&#xA;&lt;h2 id=&#34;nginx-ingress-controller-的问题&#34;&gt;nginx ingress controller 的问题&lt;/h2&gt;&#xA;&lt;h3 id=&#34;zero-downtime-pods-upgrade&#34;&gt;zero-downtime pods upgrade&lt;/h3&gt;&#xA;&lt;p&gt;默认配置下, nginx ingress controller 的 upstream 是 service 的 endpoints, 在 eks 里, 就是 vpc cni plugin 分配给 pod 的 vpc ip(不是 cluster ip),&#xA;和直接使用 service cluster ip 比, 好处是:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;可以支持 sticky session&lt;/li&gt;&#xA;&lt;li&gt;可以用 round robin 之外的负载均衡算法&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;具体实现是, 当 service 的 endpoint 列表发生变化时, nginx ingress controller 收到通知, 对它管理的 nginx 进程发起一个 http request, 更新 endpoint ip&#xA;list(nginx 内置的 lua 来修改内存中的 ip list)&lt;/p&gt;&#xA;&lt;p&gt;这样的问题是, 从 pod 被干掉到 nginx 更新之间有个时间差, 部分请求会挂掉, 解决方法可以给 pod 设置一个 preStop hook, sleep 几秒, 等 nginx ingress controller&#xA;更新完成.&lt;/p&gt;</description>
    </item>
    <item>
      <title>K8S: 剩下的问题</title>
      <link>https://blog.monsterxx03.com/2019/06/30/k8s-%E5%89%A9%E4%B8%8B%E7%9A%84%E9%97%AE%E9%A2%98/</link>
      <pubDate>Sun, 30 Jun 2019 16:11:06 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2019/06/30/k8s-%E5%89%A9%E4%B8%8B%E7%9A%84%E9%97%AE%E9%A2%98/</guid>
      <description>&lt;p&gt;准备工作都差不多了, 没意外下周就该开始把线上的服务往 k8s 上迁移了. 记录几个问题，暂时不 block 我的迁移进程,&#xA;但需要持续关注.&lt;/p&gt;&#xA;&lt;h2 id=&#34;dns-timeout-and-conntrack&#34;&gt;DNS timeout and conntrack&lt;/h2&gt;&#xA;&lt;p&gt;看到有个关于 DNS 的issue: &lt;a href=&#34;https://github.com/kubernetes/kubernetes/issues/56903&#34;&gt;#56903&lt;/a&gt;&lt;/p&gt;&#xA;&lt;p&gt;现象是 k8s cluster 内部 dns 查询间歇性会 5s 超时, 大致原因是 coredns 作为中心 dns 的时候,&#xA;要通过 iptables 把　coredns 的 cluster ip, 转化到它真实的可路由 ip, 中间需要 SNAT, DNAT, 并在&#xA;conntrack 内记录映射关系.&lt;/p&gt;&#xA;&lt;p&gt;这可能会带来两个问题:&lt;/p&gt;&#xA;&lt;h3 id=&#34;conntrack-table-被-udp-的-dns-查询填满&#34;&gt;conntrack table 被 udp 的 dns 查询填满&lt;/h3&gt;&#xA;&lt;p&gt;udp 是无连接的, tcp 关闭链接就会清理 conntrack 内记录, udp 不会，只能等超时, 默认 30s(&lt;code&gt;net.netfilter.nf_conntrack_udp_timeout&lt;/code&gt;)&#xA;短时间内大量 udp 查询可能填满 conntrack, 导致丢包.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Random Talk</title>
      <link>https://blog.monsterxx03.com/2019/05/30/random-talk/</link>
      <pubDate>Thu, 30 May 2019 18:48:23 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2019/05/30/random-talk/</guid>
      <description>&lt;p&gt;Just some random complains and notes about server infra management. I think those are my motivations to move to kubernetes.&lt;/p&gt;&#xA;&lt;p&gt;Won&amp;rsquo;t explain k8s or docker in detail, and how they solve those problems in this post.&lt;/p&gt;&#xA;&lt;h2 id=&#34;infrastructure-levelon-aws&#34;&gt;Infrastructure level(on AWS)&lt;/h2&gt;&#xA;&lt;p&gt;We use following services provided by AWS.&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Compute:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;EC2&lt;/li&gt;&#xA;&lt;li&gt;AutoScaling Group&lt;/li&gt;&#xA;&lt;li&gt;Lambda&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;network:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;VPC (SDN network)&lt;/li&gt;&#xA;&lt;li&gt;DNS (route53)&lt;/li&gt;&#xA;&lt;li&gt;CDN (CloudFront)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Loadbalancer:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ELB (L4)&lt;/li&gt;&#xA;&lt;li&gt;NLB (L4, ELB successor, support static IP)&lt;/li&gt;&#xA;&lt;li&gt;ALB (L7)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Storage:&#xA;&lt;ul&gt;&#xA;&lt;li&gt;EBS (block storage)&lt;/li&gt;&#xA;&lt;li&gt;EFS (hosted NFS)&lt;/li&gt;&#xA;&lt;li&gt;RDS(MySQl/PostgreSQL &amp;hellip;)&lt;/li&gt;&#xA;&lt;li&gt;Redshift (data warehouse)&lt;/li&gt;&#xA;&lt;li&gt;DynamoDB (KV)&lt;/li&gt;&#xA;&lt;li&gt;S3 (object storage)&lt;/li&gt;&#xA;&lt;li&gt;Glacier (cheap archive storage)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Web Firewall (WAF)&lt;/li&gt;&#xA;&lt;li&gt;Monitor (CloudWatch)&lt;/li&gt;&#xA;&lt;li&gt;DMS (ETL)&#xA;&amp;hellip;&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;For infra management, in early days, we just click, click, click&amp;hellip; or write some simple scripts to call AWS api.&lt;/p&gt;&#xA;&lt;p&gt;With infra resources growing, management became complex, a concept called &lt;code&gt;Infrastructure as Code&lt;/code&gt; rising.&lt;/p&gt;&#xA;&lt;p&gt;AWS provides CloudFormation as orchestration tool, but we use &lt;a href=&#34;https://www.terraform.io/&#34;&gt;terraform&lt;/a&gt; (for short: CloudFormation sucks, for long: &lt;a href=&#34;https://blog.monsterxx03.com/2017/04/21/infrastructure-as-code/&#34;&gt;Infrastructure as Code&lt;/a&gt;)&lt;/p&gt;&#xA;&lt;p&gt;So far, not bad.(tweak those services internally is another story&amp;hellip; never belive &lt;code&gt;work out of box&lt;/code&gt;)&lt;/p&gt;&#xA;&lt;h2 id=&#34;application-level&#34;&gt;Application level&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;configuration management (setup nginx, jenkins, redis, twemproxy, ElasticSearch or WTF..)&lt;/li&gt;&#xA;&lt;li&gt;CI/CD&lt;/li&gt;&#xA;&lt;li&gt;dependency management&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;They&amp;rsquo;re complicated, people developped bunch of tools to handle: puppet, chef, ansible, saltstack &amp;hellip;&lt;/p&gt;&#xA;&lt;p&gt;They&amp;rsquo;re great and working, but writing correct code still a challenge when changes involves:&lt;/p&gt;</description>
    </item>
    <item>
      <title>Centralized Logging on K8S</title>
      <link>https://blog.monsterxx03.com/2019/05/26/centralized-logging-on-k8s/</link>
      <pubDate>Sun, 26 May 2019 14:27:38 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2019/05/26/centralized-logging-on-k8s/</guid>
      <description>&lt;p&gt;搞定了监控, 下一步在 k8s 上要做的是中心化日志, 大体看了下, 感兴趣的有两个选择: ELK 套件, 或fluent-bit + fluentd.&lt;/p&gt;&#xA;&lt;p&gt;ELK 那套好处是, 可以把监控和日志一体化, filebeat 收集日志, metricbeat 收集 metrics, 统一存储在 ElasticSearch 里, 通过第三方项目&lt;a href=&#34;https://github.com/Yelp/elastalert&#34;&gt;elastalert&lt;/a&gt;&#xA;可以做报警，也能在 kibana 里集成界面. 坏处是 ElasticSearch 存储成本高, 吃资源. 我们对存储的日志使用需求基本就是 debug, 没有特别复杂的BI需求, 上一整套 ELK 还是太重了.&lt;/p&gt;&#xA;&lt;p&gt;选择 fluent-bit + fluentd 还有个好处是, 之前内部有套收集 metrics(用于统计 DAU, retention 之类指标) 的系统本来就是基于 fluentd 的, 用这套就不用改 metrics 那边的 ETL 了.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Prometheus on K8S</title>
      <link>https://blog.monsterxx03.com/2019/05/14/prometheus-on-k8s/</link>
      <pubDate>Tue, 14 May 2019 13:52:02 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2019/05/14/prometheus-on-k8s/</guid>
      <description>&lt;h1 id=&#34;why-move-to-prometheus&#34;&gt;Why move to prometheus?&lt;/h1&gt;&#xA;&lt;p&gt;把生产环境迁移到 k8s 的第一步是要搞定监控, 目前线上监控用的是商业的 datadog, 在 container 环境下&#xA;datadog 监控还要按 container 数目收费, 单 host 只有 10 个的额度, 超过要加钱, 高密度部署下很不划算.&#xA;一个 server 跑 20 个以上 container 是很正常的事情, 单台 server 的监控费用立马翻倍.&lt;/p&gt;&#xA;&lt;p&gt;tracing 这块之前用的也是 datadog, 但太贵了,一直也想换开源实现, 索性监控报警也换了, 踩一把坑吧.&lt;/p&gt;&#xA;&lt;p&gt;vendor lock 总是不爽的&amp;hellip;&lt;/p&gt;&#xA;&lt;h1 id=&#34;metrics-in-k8s&#34;&gt;Metrics in k8s&lt;/h1&gt;&#xA;&lt;p&gt;先不提 prometheus, k8s 中 metrics 来源有那么几个:&lt;/p&gt;&#xA;&lt;h2 id=&#34;metrics-serever&#34;&gt;metrics-serever&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes-incubator/metrics-server&#34;&gt;metrics-server&lt;/a&gt; (取代 heapster), 从 node&#xA;上 kubelet 的 &lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/stats/v1alpha1/types.go&#34;&gt;summary api&lt;/a&gt; 抓取数据(node/pod 的 cpu/memory 信息), kubectl top 和 kube-dashboard 的 metrics 数据来源就是它, horizontal pod&#xA;autoscaler 做 scale up/down 决策的数据来源也是它, metrics-server 只在内存里保留 node 和 pod 的最新值.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Jenkins on K8S</title>
      <link>https://blog.monsterxx03.com/2019/04/29/jenkins-on-k8s/</link>
      <pubDate>Mon, 29 Apr 2019 15:56:12 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2019/04/29/jenkins-on-k8s/</guid>
      <description>&lt;p&gt;最近在把 jenkins 迁移到 k8s, 具体怎么 setup 的不赘述了(helm chart, jenkins home 目录挂pvc, jenkins kubernetes-plugin).&lt;/p&gt;&#xA;&lt;p&gt;jenkins 跑 k8s 好处是可以方便得做分布式 build, 每次 trigger 一个 job 的时候自动起一个 pod 作为 jenkins slave agent, 结束了自动删掉.&#xA;在 aws 上结合 cluster-autoscaler 可以极大得扩展 ci 的并行能力, 降低成本.&lt;/p&gt;&#xA;&lt;p&gt;记录一点过程中的坑.&lt;/p&gt;&#xA;&lt;p&gt;装上 &lt;a href=&#34;https://github.com/jenkinsci/kubernetes-plugin&#34;&gt;kubernetes-plugin&lt;/a&gt; 后,要想让 jenkins 的 job 在 pod 中跑, 必须用 pipeline 的方式编写 job 定义. script 和 declarative&#xA;两种方式都支持启动 pod. 如果用 shell 的方式编写, 不会跑在 pod 里，会直接在　master 的　workspace 里 build.&lt;/p&gt;&#xA;&lt;p&gt;declarative 方式的例子:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;pipeline {&#xA;    agent {&#xA;        kubernetes  {&#xA;            label &#39;test-deploy&#39;&#xA;            yamlFile &#39;test-deploy.yaml&#39;&#xA;        }&#xA;    }&#xA;    stages {&#xA;        stage(&#39;stage test&#39;) {&#xA;            steps(&#39;tests&#39;) {&#xA;                container(&#39;test&#39;) {&#xA;                    sh &#39;ls&#39;&#xA;                }&#xA;            }&#xA;        }&#xA;    }&#xA;}&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;ls&lt;/code&gt; 命令就会在 test container 里执行, 如果不用 &lt;code&gt;container()&lt;/code&gt; step 的话，默认会在 pod 的 default container 里执行.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS Aurora DB</title>
      <link>https://blog.monsterxx03.com/2018/10/31/aws-aurora-db/</link>
      <pubDate>Wed, 31 Oct 2018 15:23:45 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2018/10/31/aws-aurora-db/</guid>
      <description>&lt;p&gt;最近在把部分用 RDS 的 MySQL 迁移到 aurora 上去, 读了下 aurora 的 paper, 顺便和 RDS 的架构做些对比.&lt;/p&gt;&#xA;&lt;h2 id=&#34;paper-notes&#34;&gt;Paper notes&lt;/h2&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;存储计算分离&lt;/li&gt;&#xA;&lt;li&gt;redo log 下推到存储层&lt;/li&gt;&#xA;&lt;li&gt;副本: 6 副本 3 AZ(2 per az), 失去一个 AZ + 1 additoinal node 不会丢数据(可读不可写). 失去一个 AZ (或任意2 node) 不影响数据写入.&lt;/li&gt;&#xA;&lt;li&gt;10GB 一个 segment, 每个 segment 6 副本一个 PG (protection group), 一 AZ　两副本.&lt;/li&gt;&#xA;&lt;li&gt;在 10Gbps 的网络上, 修复一个 10GB 的segment 需要 10s.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;MySQL 一个应用层的写会在底层产生很多额外的写操作，会带来写放大问题:&lt;/p&gt;&#xA;&lt;p&gt;&lt;img src=&#34;https://blog.monsterxx03.com/posts/images/aurora-mysql-replication.png&#34; alt=&#34;&#34;&gt;&lt;/p&gt;&#xA;&lt;p&gt;redo log 用来 crash recovery, binlog 会上传 s3　用于 point in time restore.&lt;/p&gt;&#xA;&lt;p&gt;在 aurora 里，只有 redo log 会通过网络复制到各个 replica, master 会等待 4/6 replicas 完成 redo log 的写入就认为写入成功 (所以失去3副本就无法写入数据了). 其他副本会根据 redo log 重建数据(单独的 redo log applicator 进程).&lt;/p&gt;</description>
    </item>
    <item>
      <title>为 service 制定 SLO</title>
      <link>https://blog.monsterxx03.com/2018/10/15/%E4%B8%BA-service-%E5%88%B6%E5%AE%9A-slo/</link>
      <pubDate>Mon, 15 Oct 2018 11:31:05 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2018/10/15/%E4%B8%BA-service-%E5%88%B6%E5%AE%9A-slo/</guid>
      <description>&lt;p&gt;通常我们使用云服务的时候, 服务提供商会提供 SLA(Service Level Aggrement),作为他们提供的服务质量的标准(常说的几个9),达不到会进行赔偿.&#xA;比如 AWS 的计算类服务: &lt;a href=&#34;https://aws.amazon.com/compute/sla/&#34;&gt;https://aws.amazon.com/compute/sla/&lt;/a&gt; .&lt;/p&gt;&#xA;&lt;p&gt;对公司自己 host 的 service, 我们内部也需要一些技术指标来 track 我们为客户提供的服务质量如何, 这个叫做&#xA;SLO(Service Level Objective). 也可以把他当成一个对内的,没有赔偿协议的SLA.&lt;/p&gt;&#xA;&lt;h2 id=&#34;定义指标&#34;&gt;定义指标&lt;/h2&gt;&#xA;&lt;p&gt;我主要 track 两个指标:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Availability (服务的可用性)&lt;/li&gt;&#xA;&lt;li&gt;Quality (服务质量)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Availability 的定义, 以前用简单的 service  uptime 来定义, 在集群外部用一个 service check 定时 ping 我们 service　的 check endpoint,&#xA;失败就定义为 failure.&lt;/p&gt;</description>
    </item>
    <item>
      <title>EkS 评测 part-3</title>
      <link>https://blog.monsterxx03.com/2018/09/26/eks-%E8%AF%84%E6%B5%8B-part-3/</link>
      <pubDate>Wed, 26 Sep 2018 10:16:42 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2018/09/26/eks-%E8%AF%84%E6%B5%8B-part-3/</guid>
      <description>&lt;p&gt;这篇记录对 ingress 的测试.&lt;/p&gt;&#xA;&lt;p&gt;ingress 用来将外部流量导入　k8s 内的　service. 将 service 的类型设置为 LoadBalancer / NodePort 也可以将单个 service 暴露到公网, 但用 ingress 可以只使用一个公网入口,根据　host name 或　url path 来将请求分发到不同的 service.&lt;/p&gt;&#xA;&lt;p&gt;一般　k8s 内的资源都会由一个 controller 来负责它的状态管理, 都由 kube-controller-manager 负责，　但 ingress controller 不是它的一部分，需要是视情况自己选择合适的 ingress controller.&lt;/p&gt;&#xA;&lt;p&gt;在 eks 上我主要需要 &lt;a href=&#34;https://github.com/kubernetes/ingress-nginx&#34;&gt;ingress-nginx&lt;/a&gt; 和 &lt;a href=&#34;https://github.com/kubernetes-sigs/aws-alb-ingress-controller&#34;&gt;aws-alb-ingress-controller&lt;/a&gt;. 注意, nginx inc 还维护一个 &lt;a href=&#34;https://github.com/nginxinc/kubernetes-ingress&#34;&gt;kubernetes-ingress&lt;/a&gt;, 和官方那个不是一个东西， 没测试过.&lt;/p&gt;&#xA;&lt;p&gt;这里主要只测试了 ingress-nginx, 看了下内部实现, 数据的转发真扭曲&amp;hellip;.&lt;/p&gt;</description>
    </item>
    <item>
      <title>eks 评测 part-2</title>
      <link>https://blog.monsterxx03.com/2018/09/21/eks-%E8%AF%84%E6%B5%8B-part-2/</link>
      <pubDate>Fri, 21 Sep 2018 10:28:17 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2018/09/21/eks-%E8%AF%84%E6%B5%8B-part-2/</guid>
      <description>&lt;p&gt;上文测试了一下 EKS 和 cluster autoscaler, 本文记录对 persisten volume 的测试.&lt;/p&gt;&#xA;&lt;h1 id=&#34;persistentvolume&#34;&gt;PersistentVolume&lt;/h1&gt;&#xA;&lt;p&gt;创建 gp2 类型的 storageclass, 并用 annotations 设置为默认 sc, dynamic volume provision 会用到:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;kind: StorageClass&#xA;apiVersion: storage.k8s.io/v1&#xA;metadata:&#xA;    name: gp2&#xA;    annotations:&#xA;        storageclass.kubernetes.io/is-default-class: &amp;quot;true&amp;quot;&#xA;provisioner: kubernetes.io/aws-ebs&#xA;reclaimPolicy: Retain&#xA;parameters:&#xA;    type: gp2&#xA;    fsType: ext4&#xA;    encrypted: &amp;quot;true&amp;quot;&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;因为 eks 是基于 1.10.3 的, volume expansion 还是 alpha 状态, 没法自动开启(没法改 api server 配置), 所以 storageclass 的 allowVolumeExpansion, 设置了也没用.&#xA;这里 &lt;code&gt;encrypted&lt;/code&gt; 的值必须是字符串, 否则会创建失败, 而且报错莫名其妙.&lt;/p&gt;&#xA;&lt;h2 id=&#34;创建-pod-的时候指定一个已存在的-ebs-volume&#34;&gt;创建 pod 的时候指定一个已存在的 ebs volume&lt;/h2&gt;&#xA;&lt;pre&gt;&lt;code&gt;apiVersion: v1&#xA;kind: Pod&#xA;metadata:&#xA;    name: test&#xA;spec:&#xA;    volumes:&#xA;        - name: test&#xA;          awsElasticBlockStore:&#xA;              fsType: ext4&#xA;              volumeID: vol-03670d6294ccf29fd&#xA;    containers:&#xA;        - image: nginx&#xA;          name: nginx&#xA;          volumeMounts:&#xA;              - name: test&#xA;                mountPath: /mnt&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;&lt;code&gt;kubectl -it test -- /bin/bash&lt;/code&gt;  进去看一下:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;root@test:/# df -h&#xA;Filesystem      Size  Used Avail Use% Mounted on&#xA;overlay          20G  2.2G   18G  11% /&#xA;tmpfs           3.9G     0  3.9G   0% /dev&#xA;tmpfs           3.9G     0  3.9G   0% /sys/fs/cgroup&#xA;/dev/xvdcz      976M  2.6M  907M   1% /mnt&#xA;/dev/xvda1       20G  2.2G   18G  11% /etc/hosts&#xA;shm              64M     0   64M   0% /dev/shm&#xA;tmpfs           3.9G   12K  3.9G   1% /run/secrets/kubernetes.io/serviceaccount&#xA;tmpfs           3.9G     0  3.9G   0% /sys/firmware&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;那块 volume 的确绑定在 &lt;code&gt;/mnt&lt;/code&gt;&lt;/p&gt;</description>
    </item>
    <item>
      <title>EKS 评测</title>
      <link>https://blog.monsterxx03.com/2018/09/11/eks-%E8%AF%84%E6%B5%8B/</link>
      <pubDate>Tue, 11 Sep 2018 15:02:22 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2018/09/11/eks-%E8%AF%84%E6%B5%8B/</guid>
      <description>&lt;p&gt;EKS 正式 launch 还没有正经用过, 最近总算试了一把, 记录一点.&lt;/p&gt;&#xA;&lt;h2 id=&#34;setup&#34;&gt;Setup&lt;/h2&gt;&#xA;&lt;p&gt;AWS 官方的 Guide 只提供了一个 cloudformation template 来设置 worker node, 我喜欢用 terraform, 可以跟着这个文档尝试:https://www.terraform.io/docs/providers/aws/guides/eks-getting-started.html 来设置完整的 eks cluster 和管理 worker node 的 autoscaling  group.&lt;/p&gt;&#xA;&lt;p&gt;设置完 EKS 后需要添加一条 ConfigMap:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;apiVersion: v1&#xA;kind: ConfigMap&#xA;metadata:&#xA;  name: aws-auth&#xA;  namespace: kube-system&#xA;data:&#xA;  mapRoles: |&#xA;    - rolearn: arn:aws:iam::&amp;lt;account-id&amp;gt;:role/eksNodeRole&#xA;      username: system:node:{{EC2PrivateDNSName}}&#xA;      groups:&#xA;        - system:bootstrappers&#xA;        - system:nodes&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;这样 worker node 节点才能加入集群.&lt;/p&gt;&#xA;&lt;h2 id=&#34;网络&#34;&gt;网络&lt;/h2&gt;&#xA;&lt;p&gt;之前一直没有在 AWS 上尝试构建 k8s 的一个原因, 就是不喜欢 overlay 网络, 给系统带来了额外的复杂度和管理开销, VPC flowlog 看不到 pod 之间流量, 封包后 tcpdump 不好 debug 应用层流量.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS 的 K8S CNI Plugin</title>
      <link>https://blog.monsterxx03.com/2018/04/09/aws-%E7%9A%84-k8s-cni-plugin/</link>
      <pubDate>Mon, 09 Apr 2018 15:28:38 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2018/04/09/aws-%E7%9A%84-k8s-cni-plugin/</guid>
      <description>&lt;p&gt;EKS 还没有 launch, 但 AWS 先开源了自己的 CNI 插件, 简单看了下, 说说它的实现和其他 K8S 网络方案的差别.&lt;/p&gt;&#xA;&lt;p&gt;K8S 集群对网络有几个基本要求:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;container 之间网络必须可达，且不通过 NAT&lt;/li&gt;&#xA;&lt;li&gt;所有 node 必须可以和所有 container 通信, 且不通过 NAT&lt;/li&gt;&#xA;&lt;li&gt;container 自己看到的 IP, 必须和其他 container 看到的它的 ip 相同.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;flannel-in-vpc&#34;&gt;Flannel in VPC&lt;/h2&gt;&#xA;&lt;p&gt;flannel 是 K8S 的一个 CNI 插件, 在 VPC 里使用 flannel 的话, 有几个选择:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;通过 VXLAN/UDP 进行封包, 封包影响网络性能, 而且不好 debug&lt;/li&gt;&#xA;&lt;li&gt;用 aws vpc backend, 这种方式会把每台主机的 docker 网段添加进 vpc routing table, 但默认 routing table 里只能有50条规则, 所以只能 50 个 node, 可以发 ticket 提升, 但数量太多会影响 vpc 性能.&lt;/li&gt;&#xA;&lt;li&gt;host-gw, 在每个 node 上直接维护集群中所有节点的路由, 没测试过, 感觉出问题也很难 debug, 假如用 autoscaling group 管理 node 集群, 能否让 K8S 在 scale in/out 的时候修改所有节点的路由?&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;以上方式都只能利用 EC2 上的单网卡, security group 也没法作用在 pod 上.&lt;/p&gt;</description>
    </item>
    <item>
      <title>AWS lambda 的一些应用场景</title>
      <link>https://blog.monsterxx03.com/2018/03/23/aws-lambda-%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</link>
      <pubDate>Fri, 23 Mar 2018 17:40:54 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2018/03/23/aws-lambda-%E7%9A%84%E4%B8%80%E4%BA%9B%E5%BA%94%E7%94%A8%E5%9C%BA%E6%99%AF/</guid>
      <description>&lt;p&gt;这几年吹 serverless 的比较多,  在公司内部也用 lambda , 记录一下, 这东西挺有用, 但远不到万能, 场景比较有限.&lt;/p&gt;&#xA;&lt;p&gt;lambda 的代码的部署用的 &lt;a href=&#34;https://serverless.com&#34;&gt;serverless&lt;/a&gt; 框架, 本身支持多种 cloud 平台, 我们就只在 aws lambda 上了.&lt;/p&gt;&#xA;&lt;p&gt;我基本上就把 lambda 当成 trigger 和 web hook 用.&lt;/p&gt;&#xA;&lt;h2 id=&#34;和--auto-scaling-group-一起用&#34;&gt;和  auto scaling group 一起用&lt;/h2&gt;&#xA;&lt;p&gt;线上所有分组的机器都是用 auto scaling group 管理的, 只不过 stateless 的 server 开了自动伸缩, 带状态的 (ElasticSearch cluster, redis cache cluster) 只用来维护固定 size.&lt;/p&gt;&#xA;&lt;p&gt;在往一个 group 里加 server 的时候, 要做的事情挺多的, 给新 server 添加组内编号 tag, 添加内网域名, provision, 部署最新代码.&lt;/p&gt;&#xA;&lt;p&gt;这些事都用 jenkins 来做, 但怎么触发 jenkins job 呢?&lt;/p&gt;</description>
    </item>
    <item>
      <title>DynamoDB</title>
      <link>https://blog.monsterxx03.com/2017/12/15/dynamodb/</link>
      <pubDate>Fri, 15 Dec 2017 22:24:36 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2017/12/15/dynamodb/</guid>
      <description>&lt;p&gt;DynamoDB 是 AWS 的托管 NoSQL 数据库，可以当作简单的 KV 数据库使用，也可以作为文档数据库使用.&lt;/p&gt;&#xA;&lt;h2 id=&#34;data-model&#34;&gt;Data model&lt;/h2&gt;&#xA;&lt;p&gt;组织数据的单位是 table, 每张 table 必须设置 primary key, 可以设置可选的 sort key 来做索引.&lt;/p&gt;&#xA;&lt;p&gt;每条数据记作一个 item, 每个 item 含有一个或多个 attribute, 其中必须包括 primary key.&lt;/p&gt;&#xA;&lt;p&gt;attribute 对应的 value 支持以下几种类型:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Number, 由于 DynamoDB 的传输协议是 http + json, 为了跨语言的兼容性, number 一律会被转成 string 传输.&lt;/li&gt;&#xA;&lt;li&gt;Binary, 用来表示任意的二进制数据，会用 base64 encode 后传输.&lt;/li&gt;&#xA;&lt;li&gt;Boolean, true or false&lt;/li&gt;&#xA;&lt;li&gt;Null&lt;/li&gt;&#xA;&lt;li&gt;Document 类型包含 List 和 Map, 可以互相嵌套.&#xA;&lt;ul&gt;&#xA;&lt;li&gt;List, 个数无限制, 总大小不超过 400KB&lt;/li&gt;&#xA;&lt;li&gt;Map, 属性个数无限制，总大小不超过 400 KB, 嵌套层级不超过 32 级.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;/li&gt;&#xA;&lt;li&gt;Set,  一个 set 内元素数目无限制, 无序，不超过 400KB, 但必须属于同一类型, 支持 number set, binary set, string set.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;选择-primary-key&#34;&gt;选择 primary key&lt;/h2&gt;&#xA;&lt;p&gt;Table 的 primary key 支持单一的 partition key 或复合的 partition key + sort key. 不管哪种，最后的组成的primary key 在一张表中必须唯一.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Handle outage</title>
      <link>https://blog.monsterxx03.com/2017/12/10/handle-outage/</link>
      <pubDate>Sun, 10 Dec 2017 11:13:53 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2017/12/10/handle-outage/</guid>
      <description>&lt;p&gt;A few weeks ago, production environment came to an outage, solve it cost me 8 hours (from 3am to 11am) although total down time is not long, really a bad expenrience. Finally, impact was mitigated, and I&amp;rsquo;m working on a long term solution. I learned some important things from this accident.&lt;/p&gt;&#xA;&lt;h2 id=&#34;the-outage&#34;&gt;The outage&lt;/h2&gt;&#xA;&lt;p&gt;I received alarms about live performance issue at 3am, first is server latency increaing, soon some service&amp;rsquo;s health check failed due to high load.&lt;/p&gt;&#xA;&lt;p&gt;I did following:&lt;/p&gt;&#xA;&lt;ol&gt;&#xA;&lt;li&gt;Check monitor&lt;/li&gt;&#xA;&lt;li&gt;Identify the problem is caused by KV system&lt;/li&gt;&#xA;&lt;/ol&gt;&#xA;&lt;p&gt;Okay, problem is here, I know the problem is KV system&amp;rsquo;s performance issue. But I can&amp;rsquo;t figure out the root case right now, I need a temporary solution.&#xA;Straightward way is redirect traffic to slave instance. But I know it won&amp;rsquo;t work (actually it is true), I come to similar issue before, did a fix for it, but seems it doesn&amp;rsquo;t work.&lt;/p&gt;&#xA;&lt;p&gt;The real down time was not long, performance recovered to some degree soon, but latency was still high, not normal. I monitored it for long time, and tried to find out the root case until morning. Since traffic was growing when peak hour coming, performance became problem again.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Python Web 应用性能调优</title>
      <link>https://blog.monsterxx03.com/2017/07/01/python-web-%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</link>
      <pubDate>Sat, 01 Jul 2017 23:38:24 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2017/07/01/python-web-%E5%BA%94%E7%94%A8%E6%80%A7%E8%83%BD%E8%B0%83%E4%BC%98/</guid>
      <description>&lt;h1 id=&#34;python-web-应用性能调优&#34;&gt;Python web 应用性能调优&lt;/h1&gt;&#xA;&lt;p&gt;为了快速上线，早期很多代码基本是怎么方便怎么来，这样就留下了很多隐患，性能也不是很理想，python 因为 GIL 的原因，在性能上有天然劣势，即使用了 gevent/eventlet 这种协程方案，也很容易因为耗时的 CPU 操作阻塞住整个进程。前阵子对基础代码做了些重构，效果显著，记录一些。&lt;/p&gt;&#xA;&lt;p&gt;设定目标:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;性能提高了，最直接的效果当然是能用更少的机器处理相同流量，目标是关闭 20% 的 stateless webserver.&lt;/li&gt;&#xA;&lt;li&gt;尽量在框架代码上做改动，不动业务逻辑代码。&lt;/li&gt;&#xA;&lt;li&gt;低风险 (历史经验告诉我们，动态一时爽，重构火葬场&amp;hellip;.)&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;治标&#34;&gt;治标&lt;/h2&gt;&#xA;&lt;p&gt;常见场景是大家开开心心做完一个 feature， sandbox 测试也没啥问题，上线了，结果 server load 飙升，各种 timeout 都来了，要么 rollback 代码，要么加机器。问题代码在哪?&lt;/p&gt;</description>
    </item>
    <item>
      <title>Build deb repository with fpm , aptly and s3</title>
      <link>https://blog.monsterxx03.com/2017/06/23/build-deb-repository-with-fpm-aptly-and-s3/</link>
      <pubDate>Fri, 23 Jun 2017 09:40:58 +0000</pubDate>
      <guid>https://blog.monsterxx03.com/2017/06/23/build-deb-repository-with-fpm-aptly-and-s3/</guid>
      <description>&lt;p&gt;I’m lazy, I don’t want to be deb/rpm expert, I don’t want to maintain repo server. I want as less maintenance effort as possible. 🙂&lt;/p&gt;&#xA;&lt;p&gt;Combine tools fpm, aptly with aws s3, we can do it.&lt;/p&gt;&#xA;&lt;h2 id=&#34;use-fpm-to-convert-python-package-to-deb&#34;&gt;Use fpm to convert python package to deb&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://fpm.readthedocs.io/en/latest/&#34;&gt;fpm&lt;/a&gt; can transform python/gem/npm/dir/… to deb/rpm/solaris/… packages&lt;/p&gt;&#xA;&lt;p&gt;Example:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;fpm -s python -t  deb -m xyj.asmy@gmail.com --verbose  -v 0.10.1 --python-pip /usr/local/pip Flask&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;It will transform Flask 0.10.1 package to deb. Output package will be &lt;code&gt;python-flask_0.10.1_all.deb&lt;/code&gt;&lt;/p&gt;&#xA;&lt;p&gt;Notes:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;If python packages rely on some c libs like &lt;code&gt;MySQLdb&lt;/code&gt; (libmysqlclient-dev), you need to install them on the machine to build deb binary.&lt;/li&gt;&#xA;&lt;li&gt;By default fpm use easy_install to build packages, some packages like httplib2 have permission bug with easy_install, so I use pip&lt;/li&gt;&#xA;&lt;li&gt;By default, msgpack-python will be convert to &lt;code&gt;python-msgpack-python&lt;/code&gt;, I don’t like it, so add &lt;code&gt;-n python-msgpack&lt;/code&gt; to normalize the package name.&lt;/li&gt;&#xA;&lt;li&gt;Some package’s dependencies’ version number is not valid(eg: celery 3.1.25 deps pytz &amp;gt;= dev), so I replace the dependencies with &lt;code&gt;--python-disable-dependency pytz -d &#39;pytz &amp;gt;= 2016.7&#39;&lt;/code&gt;&lt;/li&gt;&#xA;&lt;li&gt;fpm will not dowload package’s dependency automatically, you need to do it by your self&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;h2 id=&#34;use-aptly-to-setup-deb-repository&#34;&gt;Use aptly to setup deb repository&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://www.aptly.info/&#34;&gt;aptly&lt;/a&gt; can help build a self host deb repository and publish it on s3.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Infrastructure as Code</title>
      <link>https://blog.monsterxx03.com/2017/04/21/infrastructure-as-code/</link>
      <pubDate>Fri, 21 Apr 2017 16:25:07 +0000</pubDate>
      <guid>https://blog.monsterxx03.com/2017/04/21/infrastructure-as-code/</guid>
      <description>&lt;p&gt;Create virtual resource on AWS is very convenient, but how to manage them will be a problem when your size grow.&lt;/p&gt;&#xA;&lt;p&gt;You will come to:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;How to explain the detail online settings for your colleagues (like: how our prod vpc is setup?what’s the DHCP option set?), navigate around AWS console is okay, but not convenient.&lt;/li&gt;&#xA;&lt;li&gt;Who did what to which resource at when? AWS have a service called &lt;code&gt;Config&lt;/code&gt;, can be used to track this change, but if you want to make things as clear as viewing git log, still a lot of works to do.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;Ideally, we should manage AWS resources like code, all changes kept in VCS, so called &lt;code&gt;Infrastructure as Code&lt;/code&gt;.&lt;/p&gt;&#xA;&lt;p&gt;I’ve tried three ways to do it:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;ansible&lt;/li&gt;&#xA;&lt;li&gt;CloudFormation&lt;/li&gt;&#xA;&lt;li&gt;terraform&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;In this article, I&amp;rsquo;ll compare them, however, the conclusion is to use terraform 🙂&lt;/p&gt;&#xA;&lt;h2 id=&#34;ansible&#34;&gt;Ansible&lt;/h2&gt;&#xA;&lt;p&gt;Provision tools, like ansible/chef/puppet, all can be used to create aws resources, but they have some common problems:&lt;/p&gt;&#xA;&lt;ul&gt;&#xA;&lt;li&gt;Hard to track changes after bootstrap.&lt;/li&gt;&#xA;&lt;li&gt;No confident what it will do to existing resources.&lt;/li&gt;&#xA;&lt;/ul&gt;&#xA;&lt;p&gt;For example, I define a security group in ansibble:&lt;/p&gt;&#xA;&lt;pre&gt;&lt;code&gt;ec2_group:&#xA;  name: &amp;quot;web&amp;quot;&#xA;  description: &amp;quot;security group in web&amp;quot;&#xA;  vpc_id: &amp;quot;vpc-xxx&amp;quot;&#xA;  region: &amp;quot;us-east-1&amp;quot;&#xA;  rules:&#xA;    - proto: tcp&#xA;      from_port: 80&#xA;      to_port: 80&#xA;      cidr_ip: 0.0.0.0/0&#xA;&lt;/code&gt;&lt;/pre&gt;&#xA;&lt;p&gt;It will create a security group named “web” in vpc-xxx. At first glance, it’s convenient and straightforward.&lt;/p&gt;</description>
    </item>
    <item>
      <title>Migrate to encrypted RDS</title>
      <link>https://blog.monsterxx03.com/2016/10/28/migrate-to-encrypted-rds/</link>
      <pubDate>Fri, 28 Oct 2016 16:17:30 +0000</pubDate>
      <guid>https://blog.monsterxx03.com/2016/10/28/migrate-to-encrypted-rds/</guid>
      <description>&lt;p&gt;最近公司在做 HIPAA Compliance 相关的事情，其中要求之一是所有db需要开启encryption.&lt;/p&gt;&#xA;&lt;p&gt;比较麻烦的是rds 的encryption 只能在创建的时候设定，无法之后修改, 所以必须对线上的db 做一次 migration.&lt;/p&gt;</description>
    </item>
    <item>
      <title>MySQL innodb buffer pool</title>
      <link>https://blog.monsterxx03.com/2016/07/16/mysql-innodb-buffer-pool/</link>
      <pubDate>Sat, 16 Jul 2016 16:07:14 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2016/07/16/mysql-innodb-buffer-pool/</guid>
      <description>&lt;p&gt;最近在对公司的 MySQL 服务器做性能优化, 一直对 innodb 的内存使用方式不是很清楚, 乘这机会做点总结.&lt;/p&gt;&#xA;&lt;p&gt;在配置 MySQL 的时候, 一般都会需要设置 &lt;em&gt;innodb_buffer_pool_size&lt;/em&gt;, 在将 MySQL 设置在单独的服务器上时, 一般会设置为物理内存的80%.&lt;/p&gt;&#xA;&lt;p&gt;之前一直疑惑 MySQL 是怎么缓存数据的(不是指query cache), 直觉应该是LRU, 但如果 query 一下从磁盘上读取大量的数据的话(全表扫描或是 mysqldump), 是不是很容易就会把热数据给踢出去?&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
