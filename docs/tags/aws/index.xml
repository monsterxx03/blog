<?xml version="1.0" encoding="utf-8" standalone="yes" ?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Aws on Shining Moon</title>
    <link>https://blog.monsterxx03.com/tags/aws/</link>
    <description>Recent content in Aws on Shining Moon</description>
    <generator>Hugo -- gohugo.io</generator>
    <copyright>monsterxx03</copyright>
    <lastBuildDate>Fri, 15 Dec 2017 22:24:36 +0800</lastBuildDate>
    
	<atom:link href="https://blog.monsterxx03.com/tags/aws/index.xml" rel="self" type="application/rss+xml" />
    
    
    <item>
      <title>DynamoDB</title>
      <link>https://blog.monsterxx03.com/2017/12/15/dynamodb/</link>
      <pubDate>Fri, 15 Dec 2017 22:24:36 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/12/15/dynamodb/</guid>
      <description>DynamoDB æ˜¯ AWS çš„æ‰˜ç®¡ NoSQL æ•°æ®åº“ï¼Œå¯ä»¥å½“ä½œç®€å•çš„ KV æ•°æ®åº“ä½¿ç”¨ï¼Œä¹Ÿå¯ä»¥ä½œä¸ºæ–‡æ¡£æ•°æ®åº“ä½¿ç”¨.
Data model ç»„ç»‡æ•°æ®çš„å•ä½æ˜¯ table, æ¯å¼  table å¿…é¡»è®¾ç½® primary key, å¯ä»¥è®¾ç½®å¯é€‰çš„ sort key æ¥åšç´¢å¼•.
æ¯æ¡æ•°æ®è®°ä½œä¸€ä¸ª item, æ¯ä¸ª item å«æœ‰ä¸€ä¸ªæˆ–å¤šä¸ª attribute, å…¶ä¸­å¿…é¡»åŒ…æ‹¬ primary key.
attribute å¯¹åº”çš„ value æ”¯æŒä»¥ä¸‹å‡ ç§ç±»å‹:
 Number, ç”±äº DynamoDB çš„ä¼ è¾“åè®®æ˜¯ http + json, ä¸ºäº†è·¨è¯­è¨€çš„å…¼å®¹æ€§, number ä¸€å¾‹ä¼šè¢«è½¬æˆ string ä¼ è¾“. Binary, ç”¨æ¥è¡¨ç¤ºä»»æ„çš„äºŒè¿›åˆ¶æ•°æ®ï¼Œä¼šç”¨ base64 encode åä¼ è¾“. Boolean, true or false Null Document ç±»å‹åŒ…å« List å’Œ Map, å¯ä»¥äº’ç›¸åµŒå¥—.  List, ä¸ªæ•°æ— é™åˆ¶, æ€»å¤§å°ä¸è¶…è¿‡ 400KB Map, å±æ€§ä¸ªæ•°æ— é™åˆ¶ï¼Œæ€»å¤§å°ä¸è¶…è¿‡ 400 KB, åµŒå¥—å±‚çº§ä¸è¶…è¿‡ 32 çº§.</description>
    </item>
    
    <item>
      <title>AWS DMS notes</title>
      <link>https://blog.monsterxx03.com/2017/10/14/aws-dms-notes/</link>
      <pubDate>Sat, 14 Oct 2017 22:33:36 +0800</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/10/14/aws-dms-notes/</guid>
      <description>AWS&amp;rsquo;s DMS (Data migration service) can be used to do incremental ETL between databases. I use it to load data from RDS (MySQL) to Redshift.
It works, but have some concerns. Take some notes when doing this project.
Prerequisites Source RDS must:
 Enable automatic backups Increase binlog remain time, call mysql.rds_set_configuration(&#39;binlog retention hours&#39;, 24); Set binlog_format to ROW. Privileges on source RDS: REPLICATION CLIENT, REPLICATION SLAVE, SELECT on replication target tables  DDL on source table Redshift has some limits on change columns:</description>
    </item>
    
    <item>
      <title>Get all invalid PTR record on  Route53</title>
      <link>https://blog.monsterxx03.com/2017/09/29/get-all-invalid-ptr-record-on-route53/</link>
      <pubDate>Fri, 29 Sep 2017 08:55:18 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/09/29/get-all-invalid-ptr-record-on-route53/</guid>
      <description>I use autoscaling group to manage stateless servers. Servers go up and down every day.
Once server is up, I will add a PTR record for it&amp;#8217;s internal ip. But when it&amp;#8217;s down, I didn&amp;#8217;t cleanup the PTR record. As times fly, a lot of invalid PTR records left in Route53.
To cleanup those PTR records realtime, you can write a lambda function, use server termination event as trigger. But how to cleanup the old records at once?</description>
    </item>
    
    <item>
      <title>Build private static website on S3</title>
      <link>https://blog.monsterxx03.com/2017/08/19/build-private-staticwebsite-on-s3/</link>
      <pubDate>Sat, 19 Aug 2017 07:28:16 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/08/19/build-private-staticwebsite-on-s3/</guid>
      <description>Build static website on S3 is very easy, but by default, it can be accessed by open internet.It will be super helpful if we can build website only available in VPC. Then we can use it to host internal deb repo, doc site&amp;#8230;
Steps are very easy, you only need VPC endpoints and S3 bucket policy.
AWS api is open to internet, if you need to access S3 in VPC, your requests will pass through VPC&amp;#8217;s internet gateway or NAT gateway.</description>
    </item>
    
    <item>
      <title>Use redshift spectrum to do query on s3</title>
      <link>https://blog.monsterxx03.com/2017/07/21/use-redshift-spectrum-to-do-query-on-s3/</link>
      <pubDate>Fri, 21 Jul 2017 03:10:58 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/07/21/use-redshift-spectrum-to-do-query-on-s3/</guid>
      <description>ä½¿ç”¨ redshift spectrum æŸ¥è¯¢ S3 æ•°æ® é€šå¸¸ä½¿ç”¨ redshift åšæ•°æ®ä»“åº“çš„æ—¶å€™è¦åšå¤§é‡çš„ ETL å·¥ä½œï¼Œä¸€èˆ¬æµç¨‹æ˜¯æŠŠå„ç§æ¥æºçš„æ•°æ®æ£é¼“æ£é¼“ä¸¢åˆ° S3 ä¸Šå»ï¼Œå†ä» S3 å€’è…¾è¿› redshift. å¦‚æœä½ æœ‰å¤§é‡çš„å†å²æ•°æ®è¦å¯¼è¿› redshiftï¼Œè¿™ä¸ªè¿‡ç¨‹å°±ä¼šå¾ˆç—›è‹¦ï¼Œredshift å¯¹ä¸€æ¬¡å€’å…¥å¤§é‡æ•°æ®å¹¶ä¸å‹å¥½ï¼Œä½ è¦åˆ†æ‰¹æ¥åšã€‚
ä»Šå¹´4æœˆçš„æ—¶å€™ï¼Œ redshift å‘å¸ƒäº†ä¸€ä¸ªæ–°åŠŸèƒ½ spectrum, å¯ä»¥ä» redshift é‡Œç›´æ¥æŸ¥è¯¢ s3 ä¸Šçš„ç»“æ„åŒ–æ•°æ®ã€‚æœ€è¿‘æŠŠéƒ¨åˆ†æ•°æ®ä»“åº“ç›´æ¥è¿ç§»åˆ°äº† spectrum, æ­£å¥½æ¥è®²è®²ã€‚
åŠ¨æœº Glow çš„æ•°æ®ä»“åº“å»ºåœ¨ redshift ä¸Šï¼Œ åˆåˆ†æˆäº†ä¸¤ä¸ªé›†ç¾¤ï¼Œä¸€ä¸ª ssd çš„é›†ç¾¤å­˜æ”¾æœ€è¿‘ 4 ä¸ªæœˆçš„æ•°æ®ï¼Œä¾›äº§å“åˆ†æï¼Œmetrics report, debug ç­‰ç­‰ adhoc çš„æŸ¥è¯¢ã€‚4ä¸ªæœˆä¹‹å‰çš„æ•°æ®å­˜æ”¾åœ¨ä¸€ä¸ª hdd çš„é›†ç¾¤é‡Œï¼Œä¾¿å®œå®¹é‡å¤§ï¼ŒæŸ¥è¯¢æ…¢ã€‚
ä½†æ˜¯æ—¶é—´é•¿äº† hdd çš„é›†ç¾¤ä¹Ÿæ˜¯æœ‰æ‰©å®¹éœ€æ±‚çš„ï¼Œè€Œä½¿ç”¨é¢‘ç‡åˆå®åœ¨æ˜¯ä¸é«˜ï¼Œå…¶å®å¾ˆæµªè´¹, è¿™å°±æ˜¯è¿ç§»åˆ° spectrum çš„åŠ¨æœºã€‚
ä½¿ç”¨ Spectrum Redshift spectrum åº•å±‚å…¶å®æ˜¯åŸºäº AWS çš„å¦ä¸€ä¸ªæœåŠ¡ athena çš„ã€‚athena æ˜¯ä¸ª Presto å’Œ Hive æ‚äº¤äº§ç‰©ï¼Œ DDL ç”¨ Hive è¯­æ³•ï¼Œ æŸ¥è¯¢ç”¨çš„ sql ç”± Presto æ”¯æŒ, æ„Ÿè§‰æ€ªæ€ªçš„ï¼Œè¿™é‡Œä¸å¤šå±•å¼€è®² athena, çŸ¥é“ redshift spectrum å…¶å®æ˜¯é€šè¿‡ athena å¯¹æ¥çš„ s3 å°±è¡Œäº†ã€‚</description>
    </item>
    
    <item>
      <title>Infrastructure as Code</title>
      <link>https://blog.monsterxx03.com/2017/04/21/infrastructure-as-code/</link>
      <pubDate>Fri, 21 Apr 2017 16:25:07 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2017/04/21/infrastructure-as-code/</guid>
      <description>&lt;p&gt;Create virtual resource on AWS is very convenient, but how to manage them will be a problem when your size grow.&lt;/p&gt;

&lt;p&gt;You will come to:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;How to explain the detail online settings for your colleagues (like: how our prod vpc is setup?what&amp;#8217;s the DHCP option set?), navigate around AWS console is okay, but not convenient.&lt;/li&gt;
&lt;li&gt;Who did what to which resource at when? AWS have a service called &lt;code&gt;Config&lt;/code&gt;, can be used to track this change, but if you want to make things as clear as viewing git log, still a lot of works to do.&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;Ideally, we should manage AWS resources like code, all changes kept in VCS, so called &lt;code&gt;Infrastructure as Code&lt;/code&gt;.&lt;/p&gt;

&lt;p&gt;I&amp;#8217;ve tried three ways to do it:&lt;/p&gt;

&lt;ul&gt;
&lt;li&gt;ansible&lt;/li&gt;
&lt;li&gt;CloudFormation&lt;/li&gt;
&lt;li&gt;terraform&lt;/li&gt;
&lt;/ul&gt;

&lt;p&gt;In this article, I&amp;#8217;ll compare them, however, the conclusion is to use terraform ğŸ™‚&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Migrate to encrypted RDS</title>
      <link>https://blog.monsterxx03.com/2016/10/28/migrate-to-encrypted-rds/</link>
      <pubDate>Fri, 28 Oct 2016 16:17:30 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/10/28/migrate-to-encrypted-rds/</guid>
      <description>&lt;p&gt;æœ€è¿‘å…¬å¸åœ¨åš HIPAA Compliance ç›¸å…³çš„äº‹æƒ…ï¼Œå…¶ä¸­è¦æ±‚ä¹‹ä¸€æ˜¯æ‰€æœ‰dbéœ€è¦å¼€å¯encryption.&lt;/p&gt;

&lt;p&gt;æ¯”è¾ƒéº»çƒ¦çš„æ˜¯rds çš„encryption åªèƒ½åœ¨åˆ›å»ºçš„æ—¶å€™è®¾å®šï¼Œæ— æ³•ä¹‹åä¿®æ”¹, æ‰€ä»¥å¿…é¡»å¯¹çº¿ä¸Šçš„db åšä¸€æ¬¡ migration.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
    <item>
      <title>Redshift as data warehouse</title>
      <link>https://blog.monsterxx03.com/2016/07/16/redshift-as-data-warehouse/</link>
      <pubDate>Sat, 16 Jul 2016 16:11:39 +0000</pubDate>
      
      <guid>https://blog.monsterxx03.com/2016/07/16/redshift-as-data-warehouse/</guid>
      <description>&lt;p&gt;Glow çš„ server infrastructure å…¨éƒ¨æ­å»ºåœ¨ AWS ä¸Šï¼Œä¸€èˆ¬è¦é€‰æ‹©ä¸€äº›åŸºç¡€æœåŠ¡çš„æ—¶å€™ï¼Œæ€»æ˜¯å…ˆçœ‹ AWS, åªè¦åŠŸèƒ½å’Œæˆæœ¬ç¬¦åˆè¦æ±‚ï¼Œä¸ä¼šç‰¹æ„é€‰æ‹©å¼€æºæ–¹æ¡ˆã€‚&lt;/p&gt;

&lt;p&gt;æ•°æ®ä»“åº“æˆ‘ä»¬é€‰æ‹©äº† AWS çš„ Redshift.&lt;/p&gt;

&lt;p&gt;åœ¨ä¸€å¹´å¤šçš„ä½¿ç”¨è¿‡ç¨‹ä¸­ Redshift çš„æ€§èƒ½å’Œç¨³å®šæ€§éƒ½ä¸é”™, å½“ç„¶ä¹Ÿæœ‰ä¸€äº›å‘, è¿™é‡Œæ•´ç†ä¸‹åœ¨ä½¿ç”¨ redshift çš„è¿‡ç¨‹ä¸­çš„ä¸€äº›ç»éªŒå’Œé‡åˆ°çš„å‘.&lt;/p&gt;

&lt;p&gt;&lt;/p&gt;</description>
    </item>
    
  </channel>
</rss>