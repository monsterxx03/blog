<?xml version="1.0" encoding="utf-8" standalone="yes"?>
<rss version="2.0" xmlns:atom="http://www.w3.org/2005/Atom">
  <channel>
    <title>Prometheus on Shining Moon</title>
    <link>https://blog.monsterxx03.com/tags/prometheus/</link>
    <description>Recent content in Prometheus on Shining Moon</description>
    <generator>Hugo</generator>
    <language>zh-cn</language>
    <copyright>monsterxx03</copyright>
    <lastBuildDate>Tue, 14 May 2019 13:52:02 +0800</lastBuildDate>
    <atom:link href="https://blog.monsterxx03.com/tags/prometheus/index.xml" rel="self" type="application/rss+xml" />
    <item>
      <title>Prometheus on K8S</title>
      <link>https://blog.monsterxx03.com/2019/05/14/prometheus-on-k8s/</link>
      <pubDate>Tue, 14 May 2019 13:52:02 +0800</pubDate>
      <guid>https://blog.monsterxx03.com/2019/05/14/prometheus-on-k8s/</guid>
      <description>&lt;h1 id=&#34;why-move-to-prometheus&#34;&gt;Why move to prometheus?&lt;/h1&gt;&#xA;&lt;p&gt;把生产环境迁移到 k8s 的第一步是要搞定监控, 目前线上监控用的是商业的 datadog, 在 container 环境下&#xA;datadog 监控还要按 container 数目收费, 单 host 只有 10 个的额度, 超过要加钱, 高密度部署下很不划算.&#xA;一个 server 跑 20 个以上 container 是很正常的事情, 单台 server 的监控费用立马翻倍.&lt;/p&gt;&#xA;&lt;p&gt;tracing 这块之前用的也是 datadog, 但太贵了,一直也想换开源实现, 索性监控报警也换了, 踩一把坑吧.&lt;/p&gt;&#xA;&lt;p&gt;vendor lock 总是不爽的&amp;hellip;&lt;/p&gt;&#xA;&lt;h1 id=&#34;metrics-in-k8s&#34;&gt;Metrics in k8s&lt;/h1&gt;&#xA;&lt;p&gt;先不提 prometheus, k8s 中 metrics 来源有那么几个:&lt;/p&gt;&#xA;&lt;h2 id=&#34;metrics-serever&#34;&gt;metrics-serever&lt;/h2&gt;&#xA;&lt;p&gt;&lt;a href=&#34;https://github.com/kubernetes-incubator/metrics-server&#34;&gt;metrics-server&lt;/a&gt; (取代 heapster), 从 node&#xA;上 kubelet 的 &lt;a href=&#34;https://github.com/kubernetes/kubernetes/blob/master/pkg/kubelet/apis/stats/v1alpha1/types.go&#34;&gt;summary api&lt;/a&gt; 抓取数据(node/pod 的 cpu/memory 信息), kubectl top 和 kube-dashboard 的 metrics 数据来源就是它, horizontal pod&#xA;autoscaler 做 scale up/down 决策的数据来源也是它, metrics-server 只在内存里保留 node 和 pod 的最新值.&lt;/p&gt;</description>
    </item>
  </channel>
</rss>
