<!DOCTYPE html>
<html lang="zh-cn" >
<head>
  <meta charset="utf-8"/>
  <meta http-equiv="X-UA-Compatible" content="IE=edge,chrome=1"/>
  <meta name="viewport" content="width=device-width, initial-scale=1"/>

  
  <meta name="author"
        content=""/>

  
  <meta name="description" content="最近在看 google 的 &lt;The Site Reliablity Workbook&gt;, 其中有一章是&quot;Manage load&quot;, 内容还挺详细的, 结合在 aws 上的经验做点笔记.
Load Balancing 流量的入口是负载均衡, 最最简单的做法是在 DNS 上做 round robin, 但这样很依赖 client, 不同的 client 可能不完全遵守 DNS 的 TTL, 当地的 ISP 也会有缓存.
google 用 anycast 技术在自己的网络中通过 BGP 给一个域名发布多个 endpoint, 共享一个 vip(virtual ip), 通过 BGP routing 来将用户的数据包发送到最近的 frontend server, 以此来减少 latency.
但只依赖 BGP 会带来两个问题:
某个地区的用户过多会给最近的 frontend server 带来过高的负载 ISP 的 BGP 路由会重计算, 当 BGP routing 变化后, 进行中的 tcp connection 会被 reset(同一个 connection 上的后续数据包被发送到不同的 server, tcp session 不存在于新 server 上) 为了解决原生 BGP anycast 的问题, google 开发了 Maglev, 即使路由发生了变化(routing flap), connection 也不断开, 把这种方式叫做 stablized anycast.
"/>
  

  

  
  <link rel="canonical" href="https://blog.monsterxx03.com/2019/02/12/%E7%AE%A1%E7%90%86%E8%B4%9F%E8%BD%BD/"/>

  

  <title>管理负载 &middot; Shining Moon</title>

  <link rel="shortcut icon" href="https://blog.monsterxx03.com/images/favicon.ico"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/animate.min.css"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/remixicon.css"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/zozo.css"/>
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/highlight.css"/>

  
  
  <link rel="stylesheet" href="https://blog.monsterxx03.com/css/home.css">
  
</head>

<body>
<div class="main animated">
  <div class="nav_container animated fadeInDown">
  <div class="site_nav" id="site_nav">
    <ul>
      
      <li>
        <a href="/">Home</a>
      </li>
      
      <li>
        <a href="/posts/">Archive</a>
      </li>
      
      <li>
        <a href="/about/">About</a>
      </li>
      
      <li>
        <a href="/tags">Tags</a>
      </li>
      
    </ul>
  </div>
  <div class="menu_icon">
    <a id="menu_icon"><i class="remixicon-links-line"></i></a>
  </div>
</div>

  <div class="header animated fadeInDown">
  <div class="site_title_container">
    <div class="site_title">
      <h1>
        <a href="https://blog.monsterxx03.com/">
          <span>Shining Moon</span>
          <img width="90px" src="https://blog.monsterxx03.com/logo.png"/>
        </a>
      </h1>
    </div>
    <div class="description">
      <p class="sub_title">百种弊病,皆从懒生</p>
      <div class="my_socials">
        <a href="https://github.com/monsterxx03" title="github" target="_blank"><i class="remixicon-github-fill"></i></a>
        <a href="/index.xml" type="application/rss+xml" title="rss" target="_blank"><i class="remixicon-rss-fill"></i></a>
      </div>
    </div>
  </div>
</div>

  <div class="content">
    <div class="post_page">
      <div class="post animated fadeInDown">
        <div class="post_title post_detail_title">
          <h2><a href='/2019/02/12/%E7%AE%A1%E7%90%86%E8%B4%9F%E8%BD%BD/'>管理负载</a></h2>
          <span class="date">2019.02.12</span>
        </div>
        <div class="post_content markdown"><p>最近在看 google 的 <code>&lt;The Site Reliablity Workbook&gt;</code>, 其中有一章是&quot;Manage load&quot;, 内容还挺详细的, 结合在 aws 上的经验做点笔记.</p>
<h2 id="load-balancing">Load Balancing</h2>
<p>流量的入口是负载均衡, 最最简单的做法是在 DNS 上做 round robin, 但这样很依赖 client, 不同的 client 可能不完全遵守 DNS 的 TTL, 当地的 ISP 也会有缓存.</p>
<p>google 用 anycast 技术在自己的网络中通过 BGP 给一个域名发布多个 endpoint, 共享一个 vip(virtual ip), 通过 BGP routing 来将用户的数据包发送到最近的 frontend server, 以此来减少 latency.</p>
<p>但只依赖 BGP 会带来两个问题:</p>
<ul>
<li>某个地区的用户过多会给最近的 frontend server 带来过高的负载</li>
<li>ISP 的 BGP 路由会重计算, 当 BGP routing 变化后, 进行中的 tcp connection 会被 reset(同一个 connection 上的后续数据包被发送到不同的 server, tcp session 不存在于新 server 上)</li>
</ul>
<p>为了解决原生 BGP anycast 的问题, google 开发了 Maglev, 即使路由发生了变化(routing flap), connection 也不断开, 把这种方式叫做 stablized anycast.</p>
<p>Maglev 是一个三层负载均衡, 管理着集群的入口流量, 放置在数据中心的 Router 后面.</p>
<p>每台 Maglev 可以将 client 端 ip 和离它最近的 google frontend server 映射起来, 如果 Maglev A 收到一个 client 数据包, 发现有比自己离用户更近的更近的 Maglev B, 就会讲数据包转发给 B (可能是由 ISP 的 BGP flap 造成的). Maglev B 收到数据包后转发给本地的 frontend server.</p>
<p><img src="/posts/images/manage-load/maglev_01.png" alt=""></p>
<p>传统的 tcp 负载均衡方案可能是主备的, 提供的冗余是 1+1, 由于每台 Maglev 都有数据包的路由信息所以每台都是对等的, Maglev 提供了 1+N 的冗余, 扩容只需直接增加 Maglev 的个数就行.</p>
<p>Maglev 的容量规划按照处理的 packet 数目来定, 而不是传统 tcp 负载均衡的 connection 数目, 实现关键是一致性 hash + connection tracking.</p>
<p>Router 收到数据包后转发给任意一台 Maglev (对等), Maglev 根据 packet 的 5 元组(source ip, port, dst ip, port, protocol type)计算 hash, 根据 hash 值在 connection tracking table 中寻找最近的 connection, 如果找到了，并且对应的 backend 还是 health 状态就重用 connection, 否则通过一致性 hash 重新寻找一个 backend.</p>
<p>放在 Maglev 后面的 http reverse proxy 是 GFE (google front end),　类似 nginx, 用来做业务层路由, ssl termination, backend health check.</p>
<p>GSLB (global software load balancer) 充当各层之间的胶水, maglev　找最近的 GFE, GFE 找最近的 backend 都是通过 GSLB.</p>
<p>GCLB (google cloud load balancing) 基于以上技术栈构建提供给 gce 用户的负载均衡方案． 用户创建 gclb 的时候,　会创建一个　vip, 并通知 Maglev, 来将发送到这个 vip 的数据包转发到最近的 GFE, GFE 再转发到用户的 backend service.</p>
<p>相比较而言 AWS 的 ELB, ALB, NLB, 就传统多了, 没有 Maglev 这么潮,也不提供跨 region 的负载均衡能力.</p>
<h3 id="pokemon-go-的扩容例子">Pokemon Go 的扩容例子</h3>
<p>书里拿 Niantic 的 Pokemon Go 在 GCE 上的扩容做了个例子,来解释这套技术栈的应用.</p>
<p>Pokemon Go 上线前, 他们预估的 traffic 是 X, 压测时候保证了他们的 infra 能在 5X 的负载之下工作. 可实际流量远超预期, 达到了 50X.</p>
<p>在 Pokemon Go 刚 launch 的时候, 负载均衡用的是 GCE 的 NLB, 和 AWS 的 NLB 一样是个 region only 的 4 层负载均衡, 挂在 NLB 后面其实就是挂在了 Maglev 后面. Niantic 的 cluster 是 kubernetes, 结构如下图:</p>
<p><img src="/posts/images/manage-load/niantic.png" alt=""></p>
<p>有如下问题:</p>
<ul>
<li>NLB (Maglev) 是在 ip 层做负载均衡, 无法阻止 SYN flood 攻击.</li>
<li>SSL termination 由 Niantic 的 nginx 来完成, 这就多了一跳.</li>
<li>nginx 会做 request buffer, 由于 Niantic 的 client 都是 mobile, 链接不稳定, 大量的 slow request 很快地耗完了 nginx 的系统资源.</li>
</ul>
<p>于是 Niantic 转向了 GCLB, 但在迁移过程中对容量估计还是不够, 峰值时候的流量比迁移前观测的高了2倍, 直接达到了 Niantic 的容量 quote. 太高的流量让大量 向 backend server 的 request 失败, load balancer 的重试机制加剧了系统压力, GFE 的 SSL 解密模块直接过载了, 导致了 GCLB 在全球范围内性能降低了 50%.
看样子 GCLB 默认情况下是不做租户隔离的.</p>
<p>Pokemon Go 的 app 在同步失败后会间隔一段固定时间进行重试, 这又给 server 带来的很高的瞬间压力, google 之后专门给 Pokemon Go 的 GCLB 做了隔离, 并扩容. Niantic 那侧将 client 端的重试算法改成了指数补偿式的, 并加入随机偏移量, 避免瞬时高峰.</p>
<h2 id="auto-scaling">Auto Scaling</h2>
<p>auto scaling 这章和我在 AWS 上的使用经验差不多, 有一些要注意的:</p>
<ul>
<li>一般 scale out 的时机是按照 cpu 计算的, 注意留好 buffer, 新 instance
进入工作状态需要时间.</li>
<li>设置好合理的 max, min size,　如果因为意外导致不停得起新 instance 或 shutdown, 不至于让 live 进入一个死循环.</li>
<li>aws 的 autoscaling group 只能简单得按照 cpu 值做 scale, 有一个潜在风险, server 在启动过程中需要做一些 provision, 如果中途挂了, 但 server 状态是 active, 此时 server 不是 up 状态, 用户流量不会过来, 但 autoscaling group 算 load 的时候仍旧把这台没工作的 server 算进去了, 拉低了整体 cpu 数值, 会导致后续的 scale out 延迟. 这种情况比较少, 目前我没有自动化处理, 直接干掉那台 server 重新 provision 一台, 最好能有办法在 service 真正 up 再之后通知 autoscaling group 把它纳入计算.</li>
</ul>
<p>References:</p>
<ul>
<li><a href="https://landing.google.com/sre/workbook/chapters/managing-load/">https://landing.google.com/sre/workbook/chapters/managing-load/</a></li>
</ul>
</div>
        <div class="post_footer">
          
          <div class="meta">
            <div class="info">
              <span class="field tags">
                <i class="remixicon-stack-line"></i>
                
                <a href="https://blog.monsterxx03.com/tags/gce/">gce</a>
                
                <a href="https://blog.monsterxx03.com/tags/aws/">aws</a>
                
                <a href="https://blog.monsterxx03.com/tags/book/">book</a>
                
              </span>
            </div>
          </div>
          
        </div>
      </div>
    <div id="disqus_thread"></div>
<script>
    window.disqus_config = function () {
    
    
    
    };
    (function() {
        if (["localhost", "127.0.0.1"].indexOf(window.location.hostname) != -1) {
            document.getElementById('disqus_thread').innerHTML = 'Disqus comments not available by default when the website is previewed locally.';
            return;
        }
        var d = document, s = d.createElement('script'); s.async = true;
        s.src = '//' + "mx03" + '.disqus.com/embed.js';
        s.setAttribute('data-timestamp', +new Date());
        (d.head || d.body).appendChild(s);
    })();
</script>
<noscript>Please enable JavaScript to view the <a href="https://disqus.com/?ref_noscript">comments powered by Disqus.</a></noscript>
<a href="https://disqus.com" class="dsq-brlink">comments powered by <span class="logo-disqus">Disqus</span></a>
      
      
    </div>
  </div>
  <a id="back_to_top" href="#" class="back_to_top"><span>△</span></a>
</div>
<footer class="footer">
  <div class="powered_by">
    <a href="https://zeuk.me">Designed by Zeuk,</a>
    <a href="http://www.gohugo.io/">Proudly published with Hugo</a>
  </div>

  <div class="footer_slogan">
    <span></span>
  </div>
</footer>



<script src="https://blog.monsterxx03.com/js/jquery-3.3.1.min.js"></script>
<script src="https://blog.monsterxx03.com/js/zozo.js"></script>
<script src="https://blog.monsterxx03.com/js/highlight.pack.js"></script>
<link  href="https://blog.monsterxx03.com/css/fancybox.min.css" rel="stylesheet">
<script src="https://blog.monsterxx03.com/js/fancybox.min.js"></script>

<script>hljs.initHighlightingOnLoad()</script>


  <script type="text/javascript" async src="https://cdn.bootcss.com/mathjax/2.7.5/MathJax.js?config=TeX-AMS-MML_HTMLorMML">
MathJax.Hub.Config({
  tex2jax: {
    inlineMath: [['$','$'], ['\\(','\\)']],
    displayMath: [['$$','$$'], ['\[\[','\]\]']],
    processEscapes: true,
    processEnvironments: true,
    skipTags: ['script', 'noscript', 'style', 'textarea', 'pre'],
    TeX: { equationNumbers: { autoNumber: "AMS" },
         extensions: ["AMSmath.js", "AMSsymbols.js"] }
  }
});

MathJax.Hub.Queue(function() {
    
    
    
    var all = MathJax.Hub.getAllJax(), i;
    for(i = 0; i < all.length; i += 1) {
        all[i].SourceElement().parentNode.className += ' has-jax';
    }
});
</script>

<style>
code.has-jax {
    font: inherit;
    font-size: 100%;
    background: inherit;
    border: inherit;
    color: #515151;
}
</style>



      <script async src="https://www.googletagmanager.com/gtag/js?id=G-P32CTT1G2G"></script>
      <script>
        var doNotTrack = false;
        if ( false ) {
          var dnt = (navigator.doNotTrack || window.doNotTrack || navigator.msDoNotTrack);
          var doNotTrack = (dnt == "1" || dnt == "yes");
        }
        if (!doNotTrack) {
          window.dataLayer = window.dataLayer || [];
          function gtag(){dataLayer.push(arguments);}
          gtag('js', new Date());
          gtag('config', 'G-P32CTT1G2G');
        }
      </script>


</body>
</html>
